<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  
<meta name="google-site-verification" content="s0oCkquJSvsBetEUl3d8nDj5jYzNitxDJALA37MiIyM" />


<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-flash.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="python爬虫,requests,正则表达式,beautifulsoup,css,xpath,lxml," />





  <link rel="alternate" href="/atom.xml" title="高级农民工" type="application/atom+xml" />






<meta name="description" content="python爬虫第1篇利用Request请求库和4种内容提取方法：正则表达式、lxml+xpath、Beatutifulsoup+css选择器、Beatutifulsoup+find_all爬取网页内容。">
<meta name="keywords" content="python爬虫,requests,正则表达式,beautifulsoup,css,xpath,lxml">
<meta property="og:type" content="article">
<meta property="og:title" content="Requests+多种方法爬取猫眼top100电影">
<meta property="og:url" content="https://www.makcyun.top/web_scraping_withpython1.html">
<meta property="og:site_name" content="高级农民工">
<meta property="og:description" content="python爬虫第1篇利用Request请求库和4种内容提取方法：正则表达式、lxml+xpath、Beatutifulsoup+css选择器、Beatutifulsoup+find_all爬取网页内容。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://pbscl931v.bkt.clouddn.com/18-8-19/49818413.jpg">
<meta property="og:image" content="http://pbscl931v.bkt.clouddn.com/18-8-19/28479553.jpg">
<meta property="og:image" content="http://pbscl931v.bkt.clouddn.com/18-8-20/66062822.jpg">
<meta property="og:image" content="http://pbscl931v.bkt.clouddn.com/18-8-19/18415362.jpg">
<meta property="og:image" content="http://pbscl931v.bkt.clouddn.com/18-8-19/84055565.jpg">
<meta property="og:image" content="http://pbscl931v.bkt.clouddn.com/18-8-19/840042.jpg">
<meta property="og:image" content="http://pbscl931v.bkt.clouddn.com/18-8-19/87341266.jpg">
<meta property="og:image" content="http://pbscl931v.bkt.clouddn.com/18-8-20/66910595.jpg">
<meta property="og:image" content="http://pbscl931v.bkt.clouddn.com/18-8-19/28479553.jpg">
<meta property="og:image" content="http://pbscl931v.bkt.clouddn.com/18-8-19/34117279.jpg">
<meta property="og:image" content="http://pbscl931v.bkt.clouddn.com/18-8-20/80083042.jpg">
<meta property="og:image" content="http://pbscl931v.bkt.clouddn.com/18-8-21/57684234.jpg">
<meta property="og:image" content="http://pbscl931v.bkt.clouddn.com/18-8-20/32342735.jpg">
<meta property="og:image" content="http://pbscl931v.bkt.clouddn.com/18-8-20/66062822.jpg">
<meta property="og:updated_time" content="2018-08-21T01:38:05.955Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Requests+多种方法爬取猫眼top100电影">
<meta name="twitter:description" content="python爬虫第1篇利用Request请求库和4种内容提取方法：正则表达式、lxml+xpath、Beatutifulsoup+css选择器、Beatutifulsoup+find_all爬取网页内容。">
<meta name="twitter:image" content="http://pbscl931v.bkt.clouddn.com/18-8-19/49818413.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://www.makcyun.top/web_scraping_withpython1.html"/>





  <title>Requests+多种方法爬取猫眼top100电影 | 高级农民工</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <meta name="baidu-site-verification" content="E65frtf6P6" />
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">高级农民工</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Beginner's Mind</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首&emsp;&emsp;页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于博主
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归&emsp;&emsp;档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标&emsp;&emsp;签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分&emsp;&emsp;类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-top">
          <a href="/top/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-signal"></i> <br />
            
            最受欢迎
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            站内搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.makcyun.top/web_scraping_withpython1.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="高级农民工">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="http://pbscl931v.bkt.clouddn.com/18-8-3/40685653.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="高级农民工">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Requests+多种方法爬取猫眼top100电影</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-20T19:18:14+08:00">
                2018-08-20
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python爬虫/" itemprop="url" rel="index">
                    <span itemprop="name">python爬虫</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/web_scraping_withpython1.html" class="leancloud_visitors" data-flag-title="Requests+多种方法爬取猫眼top100电影">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">热度&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
                 <span>℃</span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                  <span class="post-meta-divider">|</span>
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  9,078 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  41 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><b><em>python爬虫第1篇</em></b><br>利用Request请求库和4种内容提取方法：正则表达式、lxml+xpath、Beatutifulsoup+css选择器、Beatutifulsoup+find_all爬取网页内容。</p>
<a id="more"></a>  
<p><strong>摘要：</strong> 作为小白，<strong>爬虫可以说是入门python最快和最容易获得成就感的途径</strong>。因为初级爬虫的套路相对固定，常见的方法只有几种，比较好上手。最近，跟着崔庆才大佬的书：<em>python3网络爬虫开发实战</em> 学习爬虫。选取网页结构较为简单的猫眼top100电影为案例进行练习。 <strong>重点是用上述所说的4种方法提取出关键内容</strong>。一个问题采用不同的解决方法有助于拓展思维，通过不断练习就能够灵活运用。</p>
<blockquote>
<p><strong>本文知识点：</strong><br>Requsts 请求库的使用<br>beautiful+lxml两大解析库使用<br>正则表达式 、xpath、css选择器的使用  </p>
</blockquote>
<p><img src="http://pbscl931v.bkt.clouddn.com/18-8-19/49818413.jpg" alt=""></p>
<h2 id="1-为什么爬取该网页？"><a href="#1-为什么爬取该网页？" class="headerlink" title="1. 为什么爬取该网页？"></a>1. 为什么爬取该网页？</h2><ul>
<li>比较懒，不想一页页地去翻100部电影的介绍，<strong>想在一个页面内进行总体浏览</strong>（比如在excel表格中）；</li>
</ul>
<p><img src="http://pbscl931v.bkt.clouddn.com/18-8-19/28479553.jpg" alt=""></p>
<ul>
<li>想<strong>深入了解一些比较有意思的信息</strong>，比如：哪部电影的评分最高？哪位演员的作品数量最多？哪个国家/地区上榜的电影数量最多？哪一年上榜的电影作品最多等。这些信息在网页上是不那么容易能直接获得的，所以需要爬虫。</li>
</ul>
<p><img src="http://pbscl931v.bkt.clouddn.com/18-8-20/66062822.jpg" alt=""></p>
<h2 id="2-爬虫目标"><a href="#2-爬虫目标" class="headerlink" title="2. 爬虫目标"></a>2. 爬虫目标</h2><ul>
<li>从网页中提取出top100电影的电影名称、封面图片、排名、评分、演员、上映国家/地区、评分等信息，并保存为csv文本文件。</li>
<li>根据爬取结果，进行简单的可视化分析。</li>
</ul>
<p>平台：windows7 + SublimeText3</p>
<h2 id="3-爬取步骤"><a href="#3-爬取步骤" class="headerlink" title="3. 爬取步骤"></a>3. 爬取步骤</h2><h3 id="3-1-网址URL分析"><a href="#3-1-网址URL分析" class="headerlink" title="3.1. 网址URL分析"></a>3.1. 网址URL分析</h3><p>首先，打开猫眼Top100的url网址： <a href="http://maoyan.com/board/4?offset=0" target="_blank" rel="noopener"><strong>http://maoyan.com/board/4?offset=0</strong></a>。页面非常简单，所包含的信息就是上述所说的爬虫目标。下拉页面到底部，点击第2页可以看到网址变为：<strong><a href="http://maoyan.com/board/4?offset=10" target="_blank" rel="noopener">http://maoyan.com/board/4?offset=10</a></strong>。因此，可以推断出url的变化规律：offset表示偏移，10代表一个页面的电影偏移数量，即：第一页电影是从0-10，第二页电影是从11-20。因此，获取全部100部电影，只需要构造出10个url，然后依次获取网页内容，再用不同的方法提取出所需内容就可以了。<br>下面，用requests方法获取第一个页面。</p>
<h3 id="3-2-Requests获取首页数据"><a href="#3-2-Requests获取首页数据" class="headerlink" title="3.2. Requests获取首页数据"></a>3.2. Requests获取首页数据</h3><p>先定义一个获取单个页面的函数：get_one_page()，传入url参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_one_page</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        headers = &#123;</span><br><span class="line">            <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'</span>&#125;</span><br><span class="line">        <span class="comment"># 不加headers爬不了</span></span><br><span class="line">        response = requests.get(url, headers=headers)</span><br><span class="line">        <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> response.text</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line">    <span class="keyword">except</span> RequestException:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line">    <span class="comment"># try-except语句捕获异常</span></span><br></pre></td></tr></table></figure>
<p>接下来在main()函数中设置url。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    url = <span class="string">'http://maoyan.com/board/4?offset=0'</span></span><br><span class="line">    html = get_one_page(url)</span><br><span class="line">    print(html)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p>运行上述程序后，首页的源代码就被爬取下来了。如下图所示：</p>
<p><img src="http://pbscl931v.bkt.clouddn.com/18-8-19/18415362.jpg" alt=""></p>
<p>接下来就需要从整个网页中提取出几项我们需要的内容，用到的方法就是上述所说的四种方法，下面分别进行说明。</p>
<h3 id="3-3-4种内容解析提取方法"><a href="#3-3-4种内容解析提取方法" class="headerlink" title="3.3. 4种内容解析提取方法"></a>3.3. 4种内容解析提取方法</h3><h4 id="3-3-1-正则表达式提取"><a href="#3-3-1-正则表达式提取" class="headerlink" title="3.3.1. 正则表达式提取"></a>3.3.1. 正则表达式提取</h4><p>第一种是利用<strong>正则表达式</strong>提取。<br>什么是正则表达式？ 下面这串看起来乱七八糟的符号就是正则表达式的语法。</p>
<figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">'<span class="doctag">&lt;dd&gt;</span>.*?board-index.*?&gt;(\d+)<span class="doctag">&lt;/i&gt;</span>.*?data-src="(.*?)".*?name"&gt;<span class="doctag">&lt;a.*?&gt;</span>(.*?)<span class="doctag">&lt;/a&gt;</span>.*?'</span></span><br></pre></td></tr></table></figure>
<p>它是一种强大的字符串处理工具。之所以叫正则表达式，是因为它们可以识别正则字符串（regular string）。可以这么定义：“ 如果你给我的字符串符合规则，我就返回它”；“如果字符串不符合规则，我就忽略它”。通过requests抓取下来的网页是一堆大量的字符串，用它处理后便可提取出我们想要的内容。</p>
<p>如果还不了解它，可以参考下面的教程：</p>
<blockquote>
<p><a href="http://www.runoob.com/regexp/regexp-syntax.html" target="_blank" rel="noopener">http://www.runoob.com/regexp/regexp-syntax.html</a><br><a href="https://www.w3cschool.cn/regexp/zoxa1pq7.html" target="_blank" rel="noopener">https://www.w3cschool.cn/regexp/zoxa1pq7.html</a></p>
</blockquote>
<p><strong>正则表达式常用语法：</strong></p>
<style>
table th:nth-of-type(1) {
    width: 60px;
}

</style>


<table>
<thead>
<tr>
<th style="text-align:center">模式</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">\w</td>
<td style="text-align:center">匹配字母数字及下划线</td>
</tr>
<tr>
<td style="text-align:center">\W</td>
<td style="text-align:center">匹配非字母数字及下划线</td>
</tr>
<tr>
<td style="text-align:center">\s</td>
<td style="text-align:center">匹配任意空白字符，等价于 [\t\n\r\f]</td>
</tr>
<tr>
<td style="text-align:center">\S</td>
<td style="text-align:center">匹配任意非空字符</td>
</tr>
<tr>
<td style="text-align:center">\d</td>
<td style="text-align:center">匹配任意数字，等价于 [0-9]</td>
</tr>
<tr>
<td style="text-align:center">\D</td>
<td style="text-align:center">匹配任意非数字</td>
</tr>
<tr>
<td style="text-align:center">\n</td>
<td style="text-align:center">匹配一个换行符</td>
</tr>
<tr>
<td style="text-align:center">\t</td>
<td style="text-align:center">匹配一个制表符</td>
</tr>
<tr>
<td style="text-align:center">^</td>
<td style="text-align:center">匹配字符串开始位置的字符</td>
</tr>
<tr>
<td style="text-align:center">$</td>
<td style="text-align:center">匹配字符串的末尾</td>
</tr>
<tr>
<td style="text-align:center">.</td>
<td style="text-align:center">匹配任意字符，除了换行符</td>
</tr>
<tr>
<td style="text-align:center">[…]</td>
<td style="text-align:center">用来表示一组字符，单独列出：[amk] 匹配 ‘a’，’m’ 或 ‘k’</td>
</tr>
<tr>
<td style="text-align:center">[^…]</td>
<td style="text-align:center">不在 [ ] 中的字符</td>
</tr>
<tr>
<td style="text-align:center">*</td>
<td style="text-align:center">匹配前面的字符、子表达式或括号里的字符 0 次或多次</td>
</tr>
<tr>
<td style="text-align:center">+</td>
<td style="text-align:center">同上，匹配至少一次</td>
</tr>
<tr>
<td style="text-align:center">?</td>
<td style="text-align:center">同上，匹配0到1次</td>
</tr>
<tr>
<td style="text-align:center">{n}</td>
<td style="text-align:center">匹配前面的字符、子表达式或括号里的字符 n 次</td>
</tr>
<tr>
<td style="text-align:center">{n, m}</td>
<td style="text-align:center">同上，匹配 m 到n 次（包含 m 或 n）</td>
</tr>
<tr>
<td style="text-align:center">( )</td>
<td style="text-align:center">匹配括号内的表达式，也表示一个组</td>
</tr>
</tbody>
</table>
<p>下面，开始提取关键内容。右键网页-检查-Network选项，选中左边第一个文件然后定位到电影信息的相应位置，如下图：</p>
<p><img src="http://pbscl931v.bkt.clouddn.com/18-8-19/84055565.jpg" alt=""></p>
<p>可以看到每部电影的相关信息都在<strong>dd</strong>这个节点之中。所以就可以从该节点运用正则进行提取。<br>第1个要提取的内容是电影的排名。它位于class=”board-index”的<strong>i</strong>节点内。不需要提取的内容用’.*?’替代，需要提取的数字排名用（）括起来，（）里面的数字表示为（\d+）。正则表达式可以写为：</p>
<figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">'<span class="doctag">&lt;dd&gt;</span>.*?board-index.*?&gt;(\d+)<span class="doctag">&lt;/i&gt;</span>'</span></span><br></pre></td></tr></table></figure>
<p>接着，第2个需要提取的是封面图片，图片网址位于img节点的’data-src’属性中，正则表达式可写为：</p>
<figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">'<span class="class"><span class="keyword">data</span>-src="(.*?)".*?'</span></span><br></pre></td></tr></table></figure>
<p>第1和第2个正则之间的代码是不需要的，用’.*?’替代，所以这两部分合起来写就是：</p>
<figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">'<span class="variable">&lt;dd&gt;</span>.<span class="symbol">*</span>?board-index.<span class="symbol">*</span>?&gt;(\d+)<span class="variable">&lt;/i&gt;</span>.<span class="symbol">*</span>?data-src=<span class="string">"(.*?)"</span></span><br></pre></td></tr></table></figure>
<p>同理，可以依次用正则写下主演、上映时间和评分等内容,完整的正则表达式如下：</p>
<figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">'<span class="doctag">&lt;dd&gt;</span>.*?board-index.*?&gt;(\d+)<span class="doctag">&lt;/i&gt;</span>.*?data-src="(.*?)".*?name"&gt;<span class="doctag">&lt;a.*?&gt;</span>(.*?)<span class="doctag">&lt;/a&gt;</span>.*?star"&gt;(.*?)<span class="doctag">&lt;/p&gt;</span>.*?releasetime"&gt;(.*?)<span class="doctag">&lt;/p.*?integer"&gt;</span>(.*?)<span class="doctag">&lt;/i&gt;</span>.*?fraction"&gt;(.*?)<span class="doctag">&lt;/i&gt;</span>.*?<span class="doctag">&lt;/dd&gt;</span>'</span></span><br></pre></td></tr></table></figure>
<p>正则表达式写好以后，可以定义一个页面解析提取方法：parse_one_page（），用来提取内容：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_one_page</span><span class="params">(html)</span>:</span></span><br><span class="line">    pattern = re.compile(</span><br><span class="line">        <span class="string">'&lt;dd&gt;.*?board-index.*?&gt;(\d+)&lt;/i&gt;.*?data-src="(.*?)".*?name"&gt;&lt;a.*?&gt;(.*?)&lt;/a&gt;.*?star"&gt;(.*?)&lt;/p&gt;.*?releasetime"&gt;(.*?)&lt;/p.*?integer"&gt;(.*?)&lt;/i&gt;.*?fraction"&gt;(.*?)&lt;/i&gt;.*?&lt;/dd&gt;'</span>, re.S)</span><br><span class="line">    <span class="comment"># re.S表示匹配任意字符，如果不加，则无法匹配换行符</span></span><br><span class="line">    items = re.findall(pattern, html)</span><br><span class="line">    <span class="comment"># print(items)</span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="string">'index'</span>: item[<span class="number">0</span>],</span><br><span class="line">            <span class="string">'thumb'</span>: get_thumb(item[<span class="number">1</span>]),  <span class="comment"># 定义get_thumb()方法进一步处理网址</span></span><br><span class="line">            <span class="string">'name'</span>: item[<span class="number">2</span>],</span><br><span class="line">            <span class="string">'star'</span>: item[<span class="number">3</span>].strip()[<span class="number">3</span>:],</span><br><span class="line">            <span class="comment"># 'time': item[4].strip()[5:],</span></span><br><span class="line">            <span class="comment"># 用两个方法分别提取time里的日期和地区</span></span><br><span class="line">            <span class="string">'time'</span>: get_release_time(item[<span class="number">4</span>].strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'area'</span>: get_release_area(item[<span class="number">4</span>].strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'score'</span>: item[<span class="number">5</span>].strip() + item[<span class="number">6</span>].strip()</span><br><span class="line">            <span class="comment"># 评分score由整数+小数两部分组成</span></span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>Tips:</strong><br><strong>re.S:</strong>匹配任意字符，如果不加，则无法匹配换行符；<br><strong>yield:</strong>使用yield的好处是作为生成器，可以遍历迭代，并且将数据整理形成字典，输出结果美观。具体用法可参考：<a href="https://blog.csdn.net/zhangpinghao/article/details/18716275；" target="_blank" rel="noopener">https://blog.csdn.net/zhangpinghao/article/details/18716275；</a><br><strong>.strip():</strong>用于去掉字符串中的空格。</p>
</blockquote>
<p>上面程序为了便于提取内容，又定义了3个方法：get_thumb（）、get_release_time（）和 get_release_area（）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取封面大图</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_thumb</span><span class="params">(url)</span>:</span></span><br><span class="line">    pattern = re.compile(<span class="string">r'(.*?)@.*?'</span>)</span><br><span class="line">    thumb = re.search(pattern, url)</span><br><span class="line">    <span class="keyword">return</span> thumb.group(<span class="number">1</span>)</span><br><span class="line"><span class="comment"># http://p0.meituan.net/movie/5420be40e3b755ffe04779b9b199e935256906.jpg@160w_220h_1e_1c</span></span><br><span class="line"><span class="comment"># 去掉@160w_220h_1e_1c就是大图    </span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取上映时间函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_release_time</span><span class="params">(data)</span>:</span></span><br><span class="line">    pattern = re.compile(<span class="string">r'(.*?)(\(|$)'</span>)</span><br><span class="line">    items = re.search(pattern, data)</span><br><span class="line">    <span class="keyword">if</span> items <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'未知'</span></span><br><span class="line">    <span class="keyword">return</span> items.group(<span class="number">1</span>)  <span class="comment"># 返回匹配到的第一个括号(.*?)中结果即时间</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取国家/地区函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_release_area</span><span class="params">(data)</span>:</span></span><br><span class="line">    pattern = re.compile(<span class="string">r'.*\((.*)\)'</span>)</span><br><span class="line">    <span class="comment"># $表示匹配一行字符串的结尾，这里就是(.*?)；\(|$,表示匹配字符串含有(,或者只有(.*?)</span></span><br><span class="line">    items = re.search(pattern, data)</span><br><span class="line">    <span class="keyword">if</span> items <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'未知'</span></span><br><span class="line">    <span class="keyword">return</span> items.group(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>Tips:</strong><br><strong>‘r’：</strong>正则前面加上’r’ 是为了告诉编译器这个string是个raw string，不要转意’\’。当一个字符串使用了正则表达式后，最好在前面加上’r’；<br><strong>‘|’ ‘$’：</strong>  正则’|’表示或’，’$’表示匹配一行字符串的结尾；<br><strong>.group(1)</strong>：意思是返回search匹配的第一个括号中的结果，即(.*?)，gropup()则返回所有结果2013-12-18(，group(1)返回’（’。</p>
</blockquote>
<p>接下来，修改main()函数来输出爬取的内容：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    url = <span class="string">'http://maoyan.com/board/4?offset=0'</span></span><br><span class="line">    html = get_one_page(url)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> parse_one_page(html):  </span><br><span class="line">        print(item)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>Tips:</strong><br><strong>if <strong> name</strong> == ‘_ _main__’:</strong>当.py文件被直接运行时，if <strong> name</strong> == ‘_ <em>main__’之下的代码块将被运行；当.py文件以模块形式被导入时，if <strong> name</strong> == ‘</em> _main__’之下的代码块不被运行。<br>参考：<a href="https://blog.csdn.net/yjk13703623757/article/details/77918633。" target="_blank" rel="noopener">https://blog.csdn.net/yjk13703623757/article/details/77918633。</a></p>
</blockquote>
<p>运行程序，就可成功地提取出所需内容，结果如下：</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">'index'</span>: <span class="string">'1'</span>, <span class="string">'thumb'</span>: <span class="string">'http://p1.meituan.net/movie/20803f59291c47e1e116c11963ce019e68711.jpg'</span>, <span class="string">'name'</span>: <span class="string">'霸王别姬'</span>, <span class="string">'star'</span>: <span class="string">'张国荣,张丰毅,巩俐'</span>, <span class="string">'time'</span>: <span class="string">'1993-01-01'</span>, <span class="string">'area'</span>: <span class="string">'中国香港'</span>, <span class="string">'score'</span>: <span class="string">'9.6'</span>&#125;</span><br><span class="line">&#123;<span class="string">'index'</span>: <span class="string">'2'</span>, <span class="string">'thumb'</span>: <span class="string">'http://p0.meituan.net/movie/54617769d96807e4d81804284ffe2a27239007.jpg'</span>, <span class="string">'name'</span>: <span class="string">'罗马假日'</span>, <span class="string">'star'</span>: <span class="string">'格利高里·派克,奥黛丽·赫本,埃迪·艾伯特'</span>, <span class="string">'time'</span>: <span class="string">'1953-09-02'</span>, <span class="string">'area'</span>: <span class="string">'美国'</span>, <span class="string">'score'</span>: <span class="string">'9.1'</span>&#125;</span><br><span class="line">&#123;<span class="string">'index'</span>: <span class="string">'3'</span>, <span class="string">'thumb'</span>: <span class="string">'http://p0.meituan.net/movie/283292171619cdfd5b240c8fd093f1eb255670.jpg'</span>, <span class="string">'name'</span>: <span class="string">'肖申克的救赎'</span>, <span class="string">'star'</span>: <span class="string">'蒂姆·罗宾斯,摩根·弗里曼,鲍勃·冈顿'</span>, <span class="string">'time'</span>: <span class="string">'1994-10-14'</span>, <span class="string">'area'</span>: <span class="string">'美国'</span>, <span class="string">'score'</span>: <span class="string">'9.5'</span>&#125;</span><br><span class="line">&#123;<span class="string">'index'</span>: <span class="string">'4'</span>, <span class="string">'thumb'</span>: <span class="string">'http://p0.meituan.net/movie/e55ec5d18ccc83ba7db68caae54f165f95924.jpg'</span>, <span class="string">'name'</span>: <span class="string">'这个杀手不太冷'</span>, <span class="string">'star'</span>: <span class="string">'让·雷诺,加里·奥德曼,娜塔莉·波特曼'</span>, <span class="string">'time'</span>: <span class="string">'1994-09-14'</span>, <span class="string">'area'</span>: <span class="string">'法国'</span>, <span class="string">'score'</span>: <span class="string">'9.5'</span>&#125;</span><br><span class="line">&#123;<span class="string">'index'</span>: <span class="string">'5'</span>, <span class="string">'thumb'</span>: <span class="string">'http://p1.meituan.net/movie/f5a924f362f050881f2b8f82e852747c118515.jpg'</span>, <span class="string">'name'</span>: <span class="string">'教父'</span>, <span class="string">'star'</span>: <span class="string">'马龙·白兰度,阿尔·帕西诺,詹姆斯·肯恩'</span>, <span class="string">'time'</span>: <span class="string">'1972-03-24'</span>, <span class="string">'area'</span>: <span class="string">'美国'</span>, <span class="string">'score'</span>: <span class="string">'9.3'</span>&#125;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">&#125;</span><br><span class="line">[Finished <span class="keyword">in</span> <span class="number">1.9</span>s]</span><br></pre></td></tr></table></figure>
<p>以上是第1种提取方法，如果还不习惯正则表达式这种复杂的语法，可以试试下面的第2种方法。</p>
<h4 id="3-3-2-lxml结合xpath提取"><a href="#3-3-2-lxml结合xpath提取" class="headerlink" title="3.3.2. lxml结合xpath提取"></a>3.3.2. lxml结合xpath提取</h4><p>该方法需要用到<strong>lxml</strong>这款解析利器，同时搭配xpath语法，利用它的的路径选择表达式，来高效提取所需内容。lxml包为第三方包，需要自行安装。如果对xpath的语法还不太熟悉，可参考下面的教程：<br><a href="http://www.w3school.com.cn/xpath/xpath_syntax.asp" target="_blank" rel="noopener">http://www.w3school.com.cn/xpath/xpath_syntax.asp</a></p>
<p><strong>xpath常用的规则</strong>    </p>
<table>
<thead>
<tr>
<th style="text-align:center">表达式</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">nodename</td>
<td style="text-align:center">选取此节点的所有子节点</td>
</tr>
<tr>
<td style="text-align:center">/</td>
<td style="text-align:center">从当前节点选取直接子节点</td>
</tr>
<tr>
<td style="text-align:center">//</td>
<td style="text-align:center">从当前节点选取子孙节点</td>
</tr>
<tr>
<td style="text-align:center">.</td>
<td style="text-align:center">选取当前节点</td>
</tr>
<tr>
<td style="text-align:center">..</td>
<td style="text-align:center">选取当前节点的父节点</td>
</tr>
<tr>
<td style="text-align:center">@</td>
<td style="text-align:center">选取属性</td>
</tr>
</tbody>
</table>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"container"</span> <span class="attr">id</span>=<span class="string">"app"</span> <span class="attr">class</span>=<span class="string">"page-board/index"</span> &gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"content"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"wrapper"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"main"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"update-time"</span>&gt;</span>2018-08-18<span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"has-fresh-text"</span>&gt;</span>已更新<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"board-content"</span>&gt;</span>榜单规则：将猫眼电影库中的经典影片，按照评分和评分人数从高到低综合排序取前100名，每天上午10点更新。相关数据来源于“猫眼电影库”。<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">dl</span> <span class="attr">class</span>=<span class="string">"board-wrapper"</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">dd</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">"board-index board-index-1"</span>&gt;</span>1<span class="tag">&lt;/<span class="name">i</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"/films/1203"</span> <span class="attr">title</span>=<span class="string">"霸王别姬"</span> <span class="attr">class</span>=<span class="string">"image-link"</span> <span class="attr">data-act</span>=<span class="string">"boarditem-click"</span> <span class="attr">data-val</span>=<span class="string">"&#123;movieId:1203&#125;"</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">"//ms0.meituan.net/mywww/image/loading_2.e3d934bf.png"</span> <span class="attr">alt</span>=<span class="string">""</span> <span class="attr">class</span>=<span class="string">"poster-default"</span> /&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">img</span> <span class="attr">data-src</span>=<span class="string">"http://p1.meituan.net/movie/20803f59291c47e1e116c11963ce019e68711.jpg@160w_220h_1e_1c"</span> <span class="attr">alt</span>=<span class="string">"霸王别姬"</span> <span class="attr">class</span>=<span class="string">"board-img"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"board-item-main"</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"board-item-content"</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"movie-item-info"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"name"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"/films/1203"</span> <span class="attr">title</span>=<span class="string">"霸王别姬"</span> <span class="attr">data-act</span>=<span class="string">"boarditem-click"</span> <span class="attr">data-val</span>=<span class="string">"&#123;movieId:1203&#125;"</span>&gt;</span>霸王别姬<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"star"</span>&gt;</span></span><br><span class="line">                主演：张国荣,张丰毅,巩俐</span><br><span class="line">        <span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"releasetime"</span>&gt;</span>上映时间：1993-01-01(中国香港)<span class="tag">&lt;/<span class="name">p</span>&gt;</span>    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"movie-item-number score-num"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"score"</span>&gt;</span><span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">"integer"</span>&gt;</span>9.<span class="tag">&lt;/<span class="name">i</span>&gt;</span><span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">"fraction"</span>&gt;</span>6<span class="tag">&lt;/<span class="name">i</span>&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span>        </span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line">      <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line">                <span class="tag">&lt;/<span class="name">dd</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">dd</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>根据截取的部分html网页，先来提取第1个电影排名信息，有两种方法。<br><strong>第一种：</strong>直接复制。<br>右键-Copy-Copy Xpath，得到xpath路径为：<strong>//*[@id=”app”]/div/div/div[1]/dl/dd[1]/i</strong>,为了能够提取到页面所有的排名信息，需进一步修改为：<strong>//*[@id=”app”]/div/div/div[1]/dl/dd/i/text()</strong>，如果想要再精简一点，可以省去中间部分绝对路径’/‘然后用相对路径’//‘代替，最后进一步修改为：<strong>//*[@id=”app”]//div//dd/i/text()</strong>。<br><img src="http://pbscl931v.bkt.clouddn.com/18-8-19/840042.jpg" alt=""></p>
<p><strong>第二种：</strong>观察网页结构自己写。<br>首先注意到<strong>id = app</strong>的div节点，因为在整个网页结构id是唯一的不会有第二个相同的，所有可以将该div节点作为xpath语法的起点，然后往下观察分别是3级div节点，可以省略写为：<strong>//div</strong>,再往下分别是是两个并列的<strong>p</strong>节点、<strong>dl</strong>节点、<strong>dd</strong>节点和最后的<strong>i</strong>节点文本。中间可以随意省略，只要保证该路径能够选择到唯一的文本值<strong>‘1’</strong>即可，例如省去p和dl节点，只保留后面的节点。这样，完整路径可以为：<strong>//*[@id=”app”]//div//dd/i/text()</strong>，和上式一样。</p>
<p><img src="http://pbscl931v.bkt.clouddn.com/18-8-19/87341266.jpg" alt=""></p>
<p>根据上述思路，可以写下其他内容的xpath路径。观察到路径的前一部分：<strong>//*[@id=”app”]//div//dd</strong>都是一样的，从后面才开始不同，因此为了能够精简代码，将前部分路径赋值为一个变量items，最终提取的代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 2 用lxml结合xpath提取内容</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_one_page2</span><span class="params">(html)</span>:</span></span><br><span class="line">    parse = etree.HTML(html)</span><br><span class="line">    items = parse.xpath(<span class="string">'//*[@id="app"]//div//dd'</span>)</span><br><span class="line">    <span class="comment"># 完整的是//*[@id="app"]/div/div/div[1]/dl/dd</span></span><br><span class="line">    <span class="comment"># print(type(items))</span></span><br><span class="line">    <span class="comment"># *代表匹配所有节点，@表示属性</span></span><br><span class="line">    <span class="comment"># 第一个电影是dd[1],要提取页面所有电影则去掉[1]</span></span><br><span class="line">    <span class="comment"># xpath://*[@id="app"]/div/div/div[1]/dl/dd[1]    </span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        <span class="keyword">yield</span>&#123;</span><br><span class="line">            <span class="string">'index'</span>: item.xpath(<span class="string">'./i/text()'</span>)[<span class="number">0</span>],</span><br><span class="line">            <span class="comment">#./i/text()前面的点表示从items节点开始</span></span><br><span class="line">            <span class="comment">#/text()提取文本</span></span><br><span class="line">            <span class="string">'thumb'</span>: get_thumb(str(item.xpath(<span class="string">'./a/img[2]/@data-src'</span>)[<span class="number">0</span>].strip())),</span><br><span class="line">            <span class="comment"># 'thumb': 要在network中定位，在elements里会写成@src而不是@data-src，从而会报list index out of range错误。</span></span><br><span class="line">            <span class="string">'name'</span>: item.xpath(<span class="string">'./a/@title'</span>)[<span class="number">0</span>],</span><br><span class="line">            <span class="string">'star'</span>: item.xpath(<span class="string">'.//p[@class = "star"]/text()'</span>)[<span class="number">0</span>].strip(),</span><br><span class="line">            <span class="string">'time'</span>: get_release_time(item.xpath(</span><br><span class="line">                <span class="string">'.//p[@class = "releasetime"]/text()'</span>)[<span class="number">0</span>].strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'area'</span>: get_release_area(item.xpath(</span><br><span class="line">                <span class="string">'.//p[@class = "releasetime"]/text()'</span>)[<span class="number">0</span>].strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'score'</span> : item.xpath(<span class="string">'.//p[@class = "score"]/i[1]/text()'</span>)[<span class="number">0</span>] + \</span><br><span class="line">            item.xpath(<span class="string">'.//p[@class = "score"]/i[2]/text()'</span>)[<span class="number">0</span>]</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>Tips:</strong><br><strong>[0]：</strong>xpath后面添加了[0]是因为返回的是只有1个字符串的list，添加[0]是将list提取为字符串，使其简洁；<br><strong>Network：</strong>要在最原始的Network选项卡中定位，而不是Elements中，不然提取不到相关内容；<br><strong>class属性：</strong>p[@class = “star”]/text()表示提取class属性为”star”的p节点的文本值；<br><strong>提取属性值：</strong>img[2]/@data-src’：提取img节点的data-src属性值，属性值后面无需添加’/text()’</p>
</blockquote>
<p>运行程序，就可成功地提取出所需内容，结果和第一种方法一样。</p>
<p>以上是第2种提取方法，如果也不太习惯xpath语法，可以试试下面的第3种方法。</p>
<h4 id="3-3-3-Beautiful-Soup-css选择器"><a href="#3-3-3-Beautiful-Soup-css选择器" class="headerlink" title="3.3.3. Beautiful Soup + css选择器"></a>3.3.3. Beautiful Soup + css选择器</h4><p>Beautiful Soup 同lxml一样，是一个非常强大的python解析库，可以从HTML或XML文件中提取效率非常高。关于它的用法，可参考下面的教程：<br><a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/" target="_blank" rel="noopener">https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/</a></p>
<p>css选择器选是一种模式，用于选择需要添加样式的元素，使用它的语法同样能够快速定位到所需节点，然后提取相应内容。使用方法可参考下面的教程：<br><a href="http://www.w3school.com.cn/cssref/css_selectors.asp" target="_blank" rel="noopener">http://www.w3school.com.cn/cssref/css_selectors.asp</a></p>
<p><strong>css选择器常用的规则</strong>  </p>
<style>
table th:nth-of-type(1) {
    width: 30%;
}

</style>

<table>
<thead>
<tr>
<th style="text-align:center">选择器</th>
<th style="text-align:center">例子</th>
<th style="text-align:center">例子描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">.class</td>
<td style="text-align:center">.intro</td>
<td style="text-align:center">选择 class=”intro” 的所有元素。</td>
</tr>
<tr>
<td style="text-align:center">#id</td>
<td style="text-align:center">#firstname</td>
<td style="text-align:center">选择 id=”firstname” 的所有元素。</td>
</tr>
<tr>
<td style="text-align:center">*</td>
<td style="text-align:center">*</td>
<td style="text-align:center">选择所有元素。</td>
</tr>
<tr>
<td style="text-align:center">element</td>
<td style="text-align:center">p</td>
<td style="text-align:center">选择所有p元素。</td>
</tr>
<tr>
<td style="text-align:center">element,element</td>
<td style="text-align:center">div,p</td>
<td style="text-align:center">选择所有div元素和所有p元素。</td>
</tr>
<tr>
<td style="text-align:center">element?element</td>
<td style="text-align:center">div p</td>
<td style="text-align:center">选择div元素内部的所有p元素。</td>
</tr>
<tr>
<td style="text-align:center">element&gt;element</td>
<td style="text-align:center">div&gt;p</td>
<td style="text-align:center">选择父元素为div元素的所有p元素。</td>
</tr>
<tr>
<td style="text-align:center">element+element</td>
<td style="text-align:center">div+p</td>
<td style="text-align:center">选择紧接在div元素之后的所有p元素。</td>
</tr>
<tr>
<td style="text-align:center">[attribute]</td>
<td style="text-align:center">[target]</td>
<td style="text-align:center">选择带有 target 属性所有元素。</td>
</tr>
<tr>
<td style="text-align:center">[attribute=value]</td>
<td style="text-align:center">[target=_blank]</td>
<td style="text-align:center">选择 target=”_blank” 的所有元素。</td>
</tr>
</tbody>
</table>
<p>下面就利用这种方法进行提取：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 3 用beautifulsoup + css选择器提取</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_one_page3</span><span class="params">(html)</span>:</span></span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">'lxml'</span>)</span><br><span class="line">    <span class="comment"># print(content)</span></span><br><span class="line">    <span class="comment"># print(type(content))</span></span><br><span class="line">    <span class="comment"># print('------------')</span></span><br><span class="line">    items = range(<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        <span class="keyword">yield</span>&#123;</span><br><span class="line"></span><br><span class="line">            <span class="string">'index'</span>: soup.select(<span class="string">'dd i.board-index'</span>)[item].string,</span><br><span class="line">            <span class="comment"># iclass节点完整地为'board-index board-index-1',写board-index即可</span></span><br><span class="line">            <span class="string">'thumb'</span>: get_thumb(soup.select(<span class="string">'a &gt; img.board-img'</span>)[item][<span class="string">"data-src"</span>]),</span><br><span class="line">            <span class="comment"># 表示a节点下面的class = board-img的img节点,注意浏览器eelement里面是src节点，而network里面是data-src节点，要用这个才能正确返回值</span></span><br><span class="line"></span><br><span class="line">            <span class="string">'name'</span>: soup.select(<span class="string">'.name a'</span>)[item].string,</span><br><span class="line">            <span class="string">'star'</span>: soup.select(<span class="string">'.star'</span>)[item].string.strip()[<span class="number">3</span>:],</span><br><span class="line">            <span class="string">'time'</span>: get_release_time(soup.select(<span class="string">'.releasetime'</span>)[item].string.strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'area'</span>: get_release_area(soup.select(<span class="string">'.releasetime'</span>)[item].string.strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'score'</span>: soup.select(<span class="string">'.integer'</span>)[item].string + soup.select(<span class="string">'.fraction'</span>)[item].string</span><br><span class="line"></span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure></p>
<p>运行上述程序，结果同第1种方法一样。</p>
<h4 id="3-3-4-Beautiful-Soup-find-all函数提取"><a href="#3-3-4-Beautiful-Soup-find-all函数提取" class="headerlink" title="3.3.4. Beautiful Soup + find_all函数提取"></a>3.3.4. Beautiful Soup + find_all函数提取</h4><p>Beautifulsoup除了和css选择器搭配，还可以直接用它自带的find_all函数进行提取。<br><strong>find_all</strong>，顾名思义，就是查询所有符合条件的元素，可以给它传入一些属性或文本来得到符合条件的元素，功能十分强大。<br>它的API如下：</p>
<figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find_all(<span class="name">name</span> , attrs , recursive , text , **kwargs)</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>常用的语法规则如下：</strong><br>soup.find_all(name=’ul’)： 查找所有<strong>ul</strong>节点，ul节点内还可以嵌套；<br>li.string和li.get_text()：都是获取<strong>li</strong>节点的文本，但推荐使用后者；<br>soup.find_all(attrs={‘id’: ‘list-1’}))：传入 attrs 参数，参数的类型是字典类型，表示查询 <strong>id</strong> 为 <strong>list-1</strong> 的节点；<br>常用的属性比如 id、class 等，可以省略attrs采用更简洁的形式，例如：<br>soup.find_all(id=’list-1’)<br>soup.find_all(class_=’element’)</p>
</blockquote>
<p>根据上述常用语法，可以提取网页中所需内容：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_one_page4</span><span class="params">(html)</span>:</span></span><br><span class="line">    soup = BeautifulSoup(html,<span class="string">'lxml'</span>)</span><br><span class="line">    items = range(<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        <span class="keyword">yield</span>&#123;</span><br><span class="line"></span><br><span class="line">            <span class="string">'index'</span>: soup.find_all(class_=<span class="string">'board-index'</span>)[item].string,</span><br><span class="line">            <span class="string">'thumb'</span>: soup.find_all(class_ = <span class="string">'board-img'</span>)[item].attrs[<span class="string">'data-src'</span>],</span><br><span class="line">            <span class="comment"># 用.get('data-src')获取图片src链接，或者用attrs['data-src']</span></span><br><span class="line">            <span class="string">'name'</span>: soup.find_all(name = <span class="string">'p'</span>,attrs = &#123;<span class="string">'class'</span> : <span class="string">'name'</span>&#125;)[item].string,</span><br><span class="line">            <span class="string">'star'</span>: soup.find_all(name = <span class="string">'p'</span>,attrs = &#123;<span class="string">'class'</span>:<span class="string">'star'</span>&#125;)[item].string.strip()[<span class="number">3</span>:],</span><br><span class="line">            <span class="string">'time'</span>: get_release_time(soup.find_all(class_ =<span class="string">'releasetime'</span>)[item].string.strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'area'</span>: get_release_time(soup.find_all(class_ =<span class="string">'releasetime'</span>)[item].string.strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'score'</span>:soup.find_all(name = <span class="string">'i'</span>,attrs = &#123;<span class="string">'class'</span>:<span class="string">'integer'</span>&#125;)[item].string.strip() + soup.find_all(name = <span class="string">'i'</span>,attrs = &#123;<span class="string">'class'</span>:<span class="string">'fraction'</span>&#125;)[item].string.strip()</span><br><span class="line"></span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>
<p>以上就是4种不同的内容提取方法。</p>
<h3 id="3-4-数据存储"><a href="#3-4-数据存储" class="headerlink" title="3.4. 数据存储"></a>3.4. 数据存储</h3><p>上述输出的结果为字典格式，可利用csv包的DictWriter函数将字典格式数据存储到csv文件中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据存储到csv</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_to_file3</span><span class="params">(item)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'猫眼top100.csv'</span>, <span class="string">'a'</span>, encoding=<span class="string">'utf_8_sig'</span>,newline=<span class="string">''</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="comment"># 'a'为追加模式（添加）</span></span><br><span class="line">        <span class="comment"># utf_8_sig格式导出csv不乱码 </span></span><br><span class="line">        fieldnames = [<span class="string">'index'</span>, <span class="string">'thumb'</span>, <span class="string">'name'</span>, <span class="string">'star'</span>, <span class="string">'time'</span>, <span class="string">'area'</span>, <span class="string">'score'</span>]</span><br><span class="line">        w = csv.DictWriter(f,fieldnames = fieldnames)</span><br><span class="line">        <span class="comment"># w.writeheader()</span></span><br><span class="line">        w.writerow(item)</span><br></pre></td></tr></table></figure>
<p>然后修改一下main()方法：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    url = <span class="string">'http://maoyan.com/board/4?offset=0'</span></span><br><span class="line">    html = get_one_page(url)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> parse_one_page(html):  </span><br><span class="line">        <span class="comment"># print(item)</span></span><br><span class="line">        write_to_csv(item)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure></p>
<p>结果如下图：<br><img src="http://pbscl931v.bkt.clouddn.com/18-8-20/66910595.jpg" alt=""></p>
<p>再将封面的图片下载下来：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_thumb</span><span class="params">(name, url,num)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = requests.get(url)</span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">'封面图/'</span> + name + <span class="string">'.jpg'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(response.content)</span><br><span class="line">            print(<span class="string">'第%s部电影封面下载完毕'</span> %num)</span><br><span class="line">            print(<span class="string">'------'</span>)</span><br><span class="line">    <span class="keyword">except</span> RequestException <span class="keyword">as</span> e:</span><br><span class="line">        print(e)</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">     <span class="comment"># 不能是w，否则会报错，因为图片是二进制数据所以要用wb</span></span><br></pre></td></tr></table></figure>
<h3 id="3-5-分页爬取"><a href="#3-5-分页爬取" class="headerlink" title="3.5. 分页爬取"></a>3.5. 分页爬取</h3><p>上面完成了一页电影数据的提取，接下来还需提取剩下9页共90部电影的数据。对网址进行遍历，给网址传入一个offset参数即可，修改如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(offset)</span>:</span></span><br><span class="line">    url = <span class="string">'http://maoyan.com/board/4?offset='</span> + str(offset)</span><br><span class="line">    html = get_one_page(url)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> parse_one_page(html):  </span><br><span class="line">        <span class="comment"># print(item)</span></span><br><span class="line">        write_to_csv(item)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        main(offset = i*<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<p>这样就完成了所有电影的爬取。结果如下：</p>
<p><img src="http://pbscl931v.bkt.clouddn.com/18-8-19/28479553.jpg" alt=""></p>
<p><img src="http://pbscl931v.bkt.clouddn.com/18-8-19/34117279.jpg" alt=""></p>
<h2 id="4-可视化分析"><a href="#4-可视化分析" class="headerlink" title="4. 可视化分析"></a>4. 可视化分析</h2><p>俗话说“文不如表，表不如图”。下面根据excel的数据结果，进行简单的数据可视化分析，并用图表呈现。</p>
<h3 id="4-1-电影评分最高top10"><a href="#4-1-电影评分最高top10" class="headerlink" title="4.1. 电影评分最高top10"></a>4.1. 电影评分最高top10</h3><p>首先，想看一看评分最高的前10部电影是哪些？</p>
<p>程序如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pylab <span class="keyword">as</span> pl  <span class="comment">#用于修改x轴坐标</span></span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">'ggplot'</span>)   <span class="comment">#默认绘图风格很难看，替换为好看的ggplot风格</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">8</span>,<span class="number">5</span>))   <span class="comment">#设置图片大小</span></span><br><span class="line">colors1 = <span class="string">'#6D6D6D'</span>  <span class="comment">#设置图表title、text标注的颜色</span></span><br><span class="line"></span><br><span class="line">columns = [<span class="string">'index'</span>, <span class="string">'thumb'</span>, <span class="string">'name'</span>, <span class="string">'star'</span>, <span class="string">'time'</span>, <span class="string">'area'</span>, <span class="string">'score'</span>]  <span class="comment">#设置表头</span></span><br><span class="line">df = pd.read_csv(<span class="string">'maoyan_top100.csv'</span>,encoding = <span class="string">"utf-8"</span>,header = <span class="keyword">None</span>,names =columns,index_col = <span class="string">'index'</span>)  <span class="comment">#打开表格</span></span><br><span class="line"><span class="comment"># index_col = 'index' 将索引设为index</span></span><br><span class="line"></span><br><span class="line">df_score = df.sort_values(<span class="string">'score'</span>,ascending = <span class="keyword">False</span>)  <span class="comment">#按得分降序排列</span></span><br><span class="line"></span><br><span class="line">name1 = df_score.name[:<span class="number">10</span>]      <span class="comment">#x轴坐标</span></span><br><span class="line">score1 = df_score.score[:<span class="number">10</span>]    <span class="comment">#y轴坐标  </span></span><br><span class="line">plt.bar(range(<span class="number">10</span>),score1,tick_label = name1)  <span class="comment">#绘制条形图，用range()能搞保持x轴正确顺序</span></span><br><span class="line">plt.ylim ((<span class="number">9</span>,<span class="number">9.8</span>))  <span class="comment">#设置纵坐标轴范围</span></span><br><span class="line">plt.title(<span class="string">'电影评分最高top10'</span>,color = colors1) <span class="comment">#标题</span></span><br><span class="line">plt.xlabel(<span class="string">'电影名称'</span>)      <span class="comment">#x轴标题</span></span><br><span class="line">plt.ylabel(<span class="string">'评分'</span>)          <span class="comment">#y轴标题</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为每个条形图添加数值标签</span></span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> enumerate(list(score1)):</span><br><span class="line">    plt.text(x,y+<span class="number">0.01</span>,<span class="string">'%s'</span> %round(y,<span class="number">1</span>),ha = <span class="string">'center'</span>,color = colors1)</span><br><span class="line"></span><br><span class="line">pl.xticks(rotation=<span class="number">270</span>)   <span class="comment">#x轴名称太长发生重叠，旋转为纵向显示</span></span><br><span class="line">plt.tight_layout()    <span class="comment">#自动控制空白边缘，以全部显示x轴名称</span></span><br><span class="line"><span class="comment"># plt.savefig('电影评分最高top10.png')   #保存图片</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<p>结果如下图：<br><img src="http://pbscl931v.bkt.clouddn.com/18-8-20/80083042.jpg" alt=""><br>可以看到：排名最高的分别是两部国产片”霸王别姬”和”大话西游”，其他还包括”肖申克的救赎”、”教父”等。<br>嗯，还好基本上都看过。</p>
<h3 id="4-2-各国家的电影数量比较"><a href="#4-2-各国家的电影数量比较" class="headerlink" title="4.2. 各国家的电影数量比较"></a>4.2. 各国家的电影数量比较</h3><p>然后，想看看100部电影都是来自哪些国家？<br>程序如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">area_count = df.groupby(by = <span class="string">'area'</span>).area.count().sort_values(ascending = <span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘图方法1</span></span><br><span class="line">area_count.plot.bar(color = <span class="string">'#4652B1'</span>)  <span class="comment">#设置为蓝紫色</span></span><br><span class="line">pl.xticks(rotation=<span class="number">0</span>)   <span class="comment">#x轴名称太长重叠，旋转为纵向</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘图方法2</span></span><br><span class="line"><span class="comment"># plt.bar(range(11),area_count.values,tick_label = area_count.index)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> enumerate(list(area_count.values)):</span><br><span class="line">    plt.text(x,y+<span class="number">0.5</span>,<span class="string">'%s'</span> %round(y,<span class="number">1</span>),ha = <span class="string">'center'</span>,color = colors1)</span><br><span class="line">plt.title(<span class="string">'各国/地区电影数量排名'</span>,color = colors1)</span><br><span class="line">plt.xlabel(<span class="string">'国家/地区'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'数量(部)'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># plt.savefig('各国(地区)电影数量排名.png')</span></span><br></pre></td></tr></table></figure></p>
<p>结果如下图：<br><img src="http://pbscl931v.bkt.clouddn.com/18-8-21/57684234.jpg" alt=""><br>可以看到，除去网站自身没有显示国家的电影以外，上榜电影被10个国家/地区”承包”了。其中，美国以30部电影的绝对优势占据第1名，其次是8部的日本，韩国第3，居然有7部上榜。<br>不得不说的是香港有5部，而内地一部都没有。。。</p>
<h3 id="4-3-电影作品数量集中的年份"><a href="#4-3-电影作品数量集中的年份" class="headerlink" title="4.3. 电影作品数量集中的年份"></a>4.3. 电影作品数量集中的年份</h3><p>接下来站在漫长的百年电影史的时间角度上，分析一下哪些年份”贡献了”最多的电影数量，也可以说是”电影大年”。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从日期中提取年份</span></span><br><span class="line">df[<span class="string">'year'</span>] = df[<span class="string">'time'</span>].map(<span class="keyword">lambda</span> x:x.split(<span class="string">'/'</span>)[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># print(df.info())</span></span><br><span class="line"><span class="comment"># print(df.head())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计各年上映的电影数量</span></span><br><span class="line">grouped_year = df.groupby(<span class="string">'year'</span>)</span><br><span class="line">grouped_year_amount = grouped_year.year.count()</span><br><span class="line">top_year = grouped_year_amount.sort_values(ascending = <span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘图</span></span><br><span class="line">top_year.plot(kind = <span class="string">'bar'</span>,color = <span class="string">'orangered'</span>) <span class="comment">#颜色设置为橙红色</span></span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> enumerate(list(top_year.values)):</span><br><span class="line">    plt.text(x,y+<span class="number">0.1</span>,<span class="string">'%s'</span> %round(y,<span class="number">1</span>),ha = <span class="string">'center'</span>,color = colors1)</span><br><span class="line">plt.title(<span class="string">'电影数量年份排名'</span>,color = colors1)</span><br><span class="line">plt.xlabel(<span class="string">'年份(年)'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'数量(部)'</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line"><span class="comment"># plt.savefig('电影数量年份排名.png')</span></span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<p>结果如下图：<br><img src="http://pbscl931v.bkt.clouddn.com/18-8-20/32342735.jpg" alt=""></p>
<p>可以看到，100部电影来自37个年份。其中2011年上榜电影数量最多，达到9部；其次是前一年的7部。回忆一下，那会儿正是上大学的头两年，可怎么感觉除了阿凡达之外，没有什么其他有印象的电影了。。。<br>另外，网上传的号称”电影史奇迹年”的1994年仅排名第6。这让我进一步对猫眼榜单的权威性产生了质疑。<br>再往后看，发现遥远的1939和1940年也有电影上榜。那会儿应该还是黑白电影时代吧，看来电影的口碑好坏跟外在的技术没有绝对的关系，质量才是王道。</p>
<h3 id="4-4-拥有电影作品数量最多的演员"><a href="#4-4-拥有电影作品数量最多的演员" class="headerlink" title="4.4 拥有电影作品数量最多的演员"></a>4.4 拥有电影作品数量最多的演员</h3><p>最后，看看前100部电影中哪些演员的作品数量最多。<br>程序如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#表中的演员位于同一列，用逗号分割符隔开。需进行分割然后全部提取到list中</span></span><br><span class="line">starlist = []</span><br><span class="line">star_total = df.star</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> df.star.str.replace(<span class="string">' '</span>,<span class="string">''</span>).str.split(<span class="string">','</span>):</span><br><span class="line">    starlist.extend(i)  </span><br><span class="line"><span class="comment"># print(starlist)</span></span><br><span class="line"><span class="comment"># print(len(starlist))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># set去除重复的演员名</span></span><br><span class="line">starall = set(starlist)</span><br><span class="line"><span class="comment"># print(starall)</span></span><br><span class="line"><span class="comment"># print(len(starall))</span></span><br><span class="line"></span><br><span class="line">starall2 = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> starall:</span><br><span class="line">    <span class="keyword">if</span> starlist.count(i)&gt;<span class="number">1</span>:</span><br><span class="line">        <span class="comment"># 筛选出电影数量超过1部的演员</span></span><br><span class="line">        starall2[i] = starlist.count(i)</span><br><span class="line"></span><br><span class="line">starall2 = sorted(starall2.items(),key = <span class="keyword">lambda</span> starlist:starlist[<span class="number">1</span>] ,reverse = <span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">starall2 = dict(starall2[:<span class="number">10</span>])  <span class="comment">#将元组转为字典格式</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘图</span></span><br><span class="line">x_star = list(starall2.keys())      <span class="comment">#x轴坐标</span></span><br><span class="line">y_star = list(starall2.values())    <span class="comment">#y轴坐标</span></span><br><span class="line"></span><br><span class="line">plt.bar(range(<span class="number">10</span>),y_star,tick_label = x_star)</span><br><span class="line">pl.xticks(rotation = <span class="number">270</span>)</span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> enumerate(y_star):</span><br><span class="line">    plt.text(x,y+<span class="number">0.1</span>,<span class="string">'%s'</span> %round(y,<span class="number">1</span>),ha = <span class="string">'center'</span>,color = colors1)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">'演员电影作品数量排名'</span>,color = colors1)</span><br><span class="line">plt.xlabel(<span class="string">'演员'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'数量(部)'</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()    </span><br><span class="line"><span class="comment"># plt.savefig('演员电影作品数量排名.png')</span></span><br></pre></td></tr></table></figure></p>
<p>结果如下图：<br><img src="http://pbscl931v.bkt.clouddn.com/18-8-20/66062822.jpg" alt=""></p>
<p>张国荣排在了第一位，这是之前没有猜到的。其次是梁朝伟和星爷，再之后是布拉德·皮特。惊奇地发现，前十名影星中，香港影星居然占了6位。有点严重怀疑这是不是香港版的top100电影。。。</p>
<p>对张国荣以7部影片的巨大优势雄霸榜单第一位感到好奇，想看看是哪7部电影。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'star1'</span>] = df[<span class="string">'star'</span>].map(<span class="keyword">lambda</span> x:x.split(<span class="string">','</span>)[<span class="number">0</span>])  <span class="comment">#提取1号演员</span></span><br><span class="line">df[<span class="string">'star2'</span>] = df[<span class="string">'star'</span>].map(<span class="keyword">lambda</span> x:x.split(<span class="string">','</span>)[<span class="number">1</span>])  <span class="comment">#提取2号演员</span></span><br><span class="line">star_most = df[(df.star1 == <span class="string">'张国荣'</span>) | (df.star2 == <span class="string">'张国荣'</span>)][[<span class="string">'star'</span>,<span class="string">'name'</span>]].reset_index(<span class="string">'index'</span>)</span><br><span class="line"><span class="comment"># |表示两个条件或查询，之后重置索引</span></span><br><span class="line">print(star_most)</span><br></pre></td></tr></table></figure></p>
<p>可以看到包括排名第1的”霸王别姬”、第17名的”春光乍泄”、第27名的”射雕英雄传之东成西就”等。<br>突然发现，好像只看过”英雄本色”。。。有时间，去看看他其他的作品。</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">     index        star              name</span><br><span class="line"><span class="number">0</span>      <span class="number">1</span>   张国荣,张丰毅,巩俐        霸王别姬</span><br><span class="line"><span class="number">1</span>     <span class="number">17</span>   张国荣,梁朝伟,张震        春光乍泄</span><br><span class="line"><span class="number">2</span>     <span class="number">27</span>  张国荣,梁朝伟,张学友  射雕英雄传之东成西就</span><br><span class="line"><span class="number">3</span>     <span class="number">37</span>  张国荣,梁朝伟,刘嘉玲        东邪西毒</span><br><span class="line"><span class="number">4</span>     <span class="number">70</span>   张国荣,王祖贤,午马        倩女幽魂</span><br><span class="line"><span class="number">5</span>     <span class="number">99</span>  张国荣,张曼玉,刘德华        阿飞正传</span><br><span class="line"><span class="number">6</span>    <span class="number">100</span>   狄龙,张国荣,周润发        英雄本色</span><br></pre></td></tr></table></figure>
<p>由于数据量有限，故仅作了上述简要的分析。</p>
<h2 id="5-完整程序"><a href="#5-完整程序" class="headerlink" title="5. 完整程序"></a>5. 完整程序</h2><p>最后，将前面爬虫的所有代码整理一下，完整的代码如下：<br>一、爬虫部分<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> requests.exceptions <span class="keyword">import</span> RequestException</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="comment"># -----------------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_one_page</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        headers = &#123;</span><br><span class="line">            <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'</span>&#125;</span><br><span class="line">        <span class="comment"># 不加headers爬不了</span></span><br><span class="line">        response = requests.get(url, headers=headers)</span><br><span class="line">        <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> response.text</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line">    <span class="keyword">except</span> RequestException:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1 用正则提取内容</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_one_page</span><span class="params">(html)</span>:</span></span><br><span class="line">    pattern = re.compile(</span><br><span class="line">        <span class="string">'&lt;dd&gt;.*?board-index.*?&gt;(\d+)&lt;/i&gt;.*?data-src="(.*?)".*?name"&gt;&lt;a.*?&gt;(.*?)&lt;/a&gt;.*?star"&gt;(.*?)&lt;/p&gt;.*?releasetime"&gt;(.*?)&lt;/p.*?integer"&gt;(.*?)&lt;/i&gt;.*?fraction"&gt;(.*?)&lt;/i&gt;.*?&lt;/dd&gt;'</span>, re.S)</span><br><span class="line">    <span class="comment"># re.S表示匹配任意字符，如果不加.无法匹配换行符</span></span><br><span class="line">    items = re.findall(pattern, html)</span><br><span class="line">    <span class="comment"># print(items)</span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="string">'index'</span>: item[<span class="number">0</span>],</span><br><span class="line">            <span class="string">'thumb'</span>: get_thumb(item[<span class="number">1</span>]),</span><br><span class="line">            <span class="string">'name'</span>: item[<span class="number">2</span>],</span><br><span class="line">            <span class="string">'star'</span>: item[<span class="number">3</span>].strip()[<span class="number">3</span>:],</span><br><span class="line">            <span class="comment"># 'time': item[4].strip()[5:],</span></span><br><span class="line">            <span class="comment"># 用函数分别提取time里的日期和地区</span></span><br><span class="line">            <span class="string">'time'</span>: get_release_time(item[<span class="number">4</span>].strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'area'</span>: get_release_area(item[<span class="number">4</span>].strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'score'</span>: item[<span class="number">5</span>].strip() + item[<span class="number">6</span>].strip()</span><br><span class="line">        &#125;</span><br><span class="line">      </span><br><span class="line"><span class="comment"># 2 用lxml结合xpath提取内容</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_one_page2</span><span class="params">(html)</span>:</span></span><br><span class="line">    parse = etree.HTML(html)</span><br><span class="line">    items = parse.xpath(<span class="string">'//*[@id="app"]//div//dd'</span>)</span><br><span class="line">    <span class="comment"># 完整的是//*[@id="app"]/div/div/div[1]/dl/dd</span></span><br><span class="line">    <span class="comment"># print(type(items))</span></span><br><span class="line">    <span class="comment"># *代表匹配所有节点，@表示属性</span></span><br><span class="line">    <span class="comment"># 第一个电影是dd[1],要提取页面所有电影则去掉[1]</span></span><br><span class="line">    <span class="comment"># xpath://*[@id="app"]/div/div/div[1]/dl/dd[1]</span></span><br><span class="line">    <span class="comment"># lst = []</span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        <span class="keyword">yield</span>&#123;</span><br><span class="line">            <span class="string">'index'</span>: item.xpath(<span class="string">'./i/text()'</span>)[<span class="number">0</span>],</span><br><span class="line">            <span class="comment">#./i/text()前面的点表示从items节点开始</span></span><br><span class="line">            <span class="comment">#/text()提取文本</span></span><br><span class="line">            <span class="string">'thumb'</span>: get_thumb(str(item.xpath(<span class="string">'./a/img[2]/@data-src'</span>)[<span class="number">0</span>].strip())),</span><br><span class="line">            <span class="comment"># 'thumb': 要在network中定位，在elements里会写成@src而不是@data-src，从而会报list index out of range错误。</span></span><br><span class="line">            <span class="string">'name'</span>: item.xpath(<span class="string">'./a/@title'</span>)[<span class="number">0</span>],</span><br><span class="line">            <span class="string">'star'</span>: item.xpath(<span class="string">'.//p[@class = "star"]/text()'</span>)[<span class="number">0</span>].strip(),</span><br><span class="line">            <span class="string">'time'</span>: get_release_time(item.xpath(</span><br><span class="line">                <span class="string">'.//p[@class = "releasetime"]/text()'</span>)[<span class="number">0</span>].strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'area'</span>: get_release_area(item.xpath(</span><br><span class="line">                <span class="string">'.//p[@class = "releasetime"]/text()'</span>)[<span class="number">0</span>].strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'score'</span> : item.xpath(<span class="string">'.//p[@class = "score"]/i[1]/text()'</span>)[<span class="number">0</span>] + \</span><br><span class="line">            item.xpath(<span class="string">'.//p[@class = "score"]/i[2]/text()'</span>)[<span class="number">0</span>]</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 3 用beautifulsoup + css选择器提取</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_one_page3</span><span class="params">(html)</span>:</span></span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">'lxml'</span>)</span><br><span class="line">    <span class="comment"># print(content)</span></span><br><span class="line">    <span class="comment"># print(type(content))</span></span><br><span class="line">    <span class="comment"># print('------------')</span></span><br><span class="line">    items = range(<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        <span class="keyword">yield</span>&#123;</span><br><span class="line"></span><br><span class="line">            <span class="string">'index'</span>: soup.select(<span class="string">'dd i.board-index'</span>)[item].string,</span><br><span class="line">            <span class="comment"># iclass节点完整地为'board-index board-index-1',写board-inde即可</span></span><br><span class="line">            <span class="string">'thumb'</span>: get_thumb(soup.select(<span class="string">'a &gt; img.board-img'</span>)[item][<span class="string">"data-src"</span>]),</span><br><span class="line">            <span class="comment"># 表示a节点下面的class = board-img的img节点,注意浏览器eelement里面是src节点，而network里面是data-src节点，要用这个才能正确返回值</span></span><br><span class="line"></span><br><span class="line">            <span class="string">'name'</span>: soup.select(<span class="string">'.name a'</span>)[item].string,</span><br><span class="line">            <span class="string">'star'</span>: soup.select(<span class="string">'.star'</span>)[item].string.strip()[<span class="number">3</span>:],</span><br><span class="line">            <span class="string">'time'</span>: get_release_time(soup.select(<span class="string">'.releasetime'</span>)[item].string.strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'area'</span>: get_release_area(soup.select(<span class="string">'.releasetime'</span>)[item].string.strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'score'</span>: soup.select(<span class="string">'.integer'</span>)[item].string + soup.select(<span class="string">'.fraction'</span>)[item].string</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4 用beautifulsoup + find_all提取</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_one_page4</span><span class="params">(html)</span>:</span></span><br><span class="line">    soup = BeautifulSoup(html,<span class="string">'lxml'</span>)</span><br><span class="line">    items = range(<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        <span class="keyword">yield</span>&#123;</span><br><span class="line"></span><br><span class="line">            <span class="string">'index'</span>: soup.find_all(class_=<span class="string">'board-index'</span>)[item].string,</span><br><span class="line">            <span class="string">'thumb'</span>: soup.find_all(class_ = <span class="string">'board-img'</span>)[item].attrs[<span class="string">'data-src'</span>],</span><br><span class="line">            <span class="comment"># 用.get('data-src')获取图片src链接，或者用attrs['data-src']</span></span><br><span class="line">            <span class="string">'name'</span>: soup.find_all(name = <span class="string">'p'</span>,attrs = &#123;<span class="string">'class'</span> : <span class="string">'name'</span>&#125;)[item].string,</span><br><span class="line">            <span class="string">'star'</span>: soup.find_all(name = <span class="string">'p'</span>,attrs = &#123;<span class="string">'class'</span>:<span class="string">'star'</span>&#125;)[item].string.strip()[<span class="number">3</span>:],</span><br><span class="line">            <span class="string">'time'</span>: get_release_time(soup.find_all(class_ =<span class="string">'releasetime'</span>)[item].string.strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'area'</span>: get_release_time(soup.find_all(class_ =<span class="string">'releasetime'</span>)[item].string.strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'score'</span>:soup.find_all(name = <span class="string">'i'</span>,attrs = &#123;<span class="string">'class'</span>:<span class="string">'integer'</span>&#125;)[item].string.strip() + soup.find_all(name = <span class="string">'i'</span>,attrs = &#123;<span class="string">'class'</span>:<span class="string">'fraction'</span>&#125;)[item].string.strip()</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># -----------------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取时间函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_release_time</span><span class="params">(data)</span>:</span></span><br><span class="line">    pattern = re.compile(<span class="string">r'(.*?)(\(|$)'</span>)</span><br><span class="line">    items = re.search(pattern, data)</span><br><span class="line">    <span class="keyword">if</span> items <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'未知'</span></span><br><span class="line">    <span class="keyword">return</span> items.group(<span class="number">1</span>)  <span class="comment"># 返回匹配到的第一个括号(.*?)中结果即时间</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取国家/地区函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_release_area</span><span class="params">(data)</span>:</span></span><br><span class="line">    pattern = re.compile(<span class="string">r'.*\((.*)\)'</span>)</span><br><span class="line">    <span class="comment"># $表示匹配一行字符串的结尾，这里就是(.*?)；\(|$,表示匹配字符串含有(,或者只有(.*?)</span></span><br><span class="line">    items = re.search(pattern, data)</span><br><span class="line">    <span class="keyword">if</span> items <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'未知'</span></span><br><span class="line">    <span class="keyword">return</span> items.group(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取封面大图</span></span><br><span class="line"><span class="comment"># http://p0.meituan.net/movie/5420be40e3b755ffe04779b9b199e935256906.jpg@160w_220h_1e_1c</span></span><br><span class="line"><span class="comment"># 去掉@160w_220h_1e_1c就是大图</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_thumb</span><span class="params">(url)</span>:</span></span><br><span class="line">    pattern = re.compile(<span class="string">r'(.*?)@.*?'</span>)</span><br><span class="line">    thumb = re.search(pattern, url)</span><br><span class="line">    <span class="keyword">return</span> thumb.group(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据存储到csv</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_to_file3</span><span class="params">(item)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'猫眼top100.csv'</span>, <span class="string">'a'</span>, encoding=<span class="string">'utf_8_sig'</span>,newline=<span class="string">''</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="comment"># 'a'为追加模式（添加）</span></span><br><span class="line">        <span class="comment"># utf_8_sig格式导出csv不乱码 </span></span><br><span class="line">        fieldnames = [<span class="string">'index'</span>, <span class="string">'thumb'</span>, <span class="string">'name'</span>, <span class="string">'star'</span>, <span class="string">'time'</span>, <span class="string">'area'</span>, <span class="string">'score'</span>]</span><br><span class="line">        w = csv.DictWriter(f,fieldnames = fieldnames)</span><br><span class="line">        <span class="comment"># w.writeheader()</span></span><br><span class="line">        w.writerow(item)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 封面下载</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_thumb</span><span class="params">(name, url,num)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = requests.get(url)</span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">'封面图/'</span> + name + <span class="string">'.jpg'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(response.content)</span><br><span class="line">            print(<span class="string">'第%s部电影封面下载完毕'</span> %num)</span><br><span class="line">            print(<span class="string">'------'</span>)</span><br><span class="line">    <span class="keyword">except</span> RequestException <span class="keyword">as</span> e:</span><br><span class="line">        print(e)</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">     <span class="comment"># 存储格式是wb,因为图片是二进制数格式，不能用w，否则会报错</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># -----------------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(offset)</span>:</span></span><br><span class="line">    url = <span class="string">'http://maoyan.com/board/4?offset='</span> + str(offset)</span><br><span class="line">    html = get_one_page(url)</span><br><span class="line">    <span class="comment"># print(html)</span></span><br><span class="line">    <span class="comment"># parse_one_page2(html)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> parse_one_page(html):  <span class="comment"># 切换内容提取方法</span></span><br><span class="line">        print(item)</span><br><span class="line">        write_to_file(item)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 下载封面图</span></span><br><span class="line">        download_thumb(item[<span class="string">'name'</span>], item[<span class="string">'thumb'</span>],item[<span class="string">'index'</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># if __name__ == '__main__':</span></span><br><span class="line"><span class="comment">#     for i in range(10):</span></span><br><span class="line"><span class="comment">#         main(i * 10)</span></span><br><span class="line">        <span class="comment"># time.sleep(0.5)</span></span><br><span class="line">        <span class="comment"># 猫眼增加了反爬虫，设置0.5s的延迟时间</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2 使用多进程提升抓取效率</span></span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Pool</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    pool = Pool()</span><br><span class="line">    pool.map(main, [i * <span class="number">10</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>)])</span><br></pre></td></tr></table></figure></p>
<p>二、可视化部分<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># 可视化分析</span></span><br><span class="line"><span class="comment"># -------------------------------</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pylab <span class="keyword">as</span> pl  <span class="comment"># 用于修改x轴坐标</span></span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">'ggplot'</span>)  <span class="comment"># 默认绘图风格很难看，替换为好看的ggplot风格</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">8</span>, <span class="number">5</span>))  <span class="comment"># 设置图片大小</span></span><br><span class="line">colors1 = <span class="string">'#6D6D6D'</span>  <span class="comment"># 设置图表title、text标注的颜色</span></span><br><span class="line">columns = [<span class="string">'index'</span>, <span class="string">'thumb'</span>, <span class="string">'name'</span>, <span class="string">'star'</span>, <span class="string">'time'</span>, <span class="string">'area'</span>, <span class="string">'score'</span>]  <span class="comment"># 设置表头</span></span><br><span class="line">df = pd.read_csv(<span class="string">'maoyan_top100.csv'</span>, encoding=<span class="string">"utf-8"</span>,</span><br><span class="line">                 header=<span class="keyword">None</span>, names=columns, index_col=<span class="string">'index'</span>)  <span class="comment"># 打开表格</span></span><br><span class="line"><span class="comment"># index_col = 'index' 将索引设为index</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1电影评分最高top10</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">annalysis_1</span><span class="params">()</span>:</span></span><br><span class="line">    df_score = df.sort_values(<span class="string">'score'</span>, ascending=<span class="keyword">False</span>)  <span class="comment"># 按得分降序排列</span></span><br><span class="line"></span><br><span class="line">    name1 = df_score.name[:<span class="number">10</span>]  <span class="comment"># x轴坐标</span></span><br><span class="line">    score1 = df_score.score[:<span class="number">10</span>]  <span class="comment"># y轴坐标</span></span><br><span class="line">    plt.bar(range(<span class="number">10</span>), score1, tick_label=name1)  <span class="comment"># 绘制条形图，用range()能搞保持x轴正确顺序</span></span><br><span class="line">    plt.ylim((<span class="number">9</span>, <span class="number">9.8</span>))  <span class="comment"># 设置纵坐标轴范围</span></span><br><span class="line">    plt.title(<span class="string">'电影评分最高top10'</span>, color=colors1)  <span class="comment"># 标题</span></span><br><span class="line">    plt.xlabel(<span class="string">'电影名称'</span>)  <span class="comment"># x轴标题</span></span><br><span class="line">    plt.ylabel(<span class="string">'评分'</span>)  <span class="comment"># y轴标题</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 为每个条形图添加数值标签</span></span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> enumerate(list(score1)):</span><br><span class="line">        plt.text(x, y + <span class="number">0.01</span>, <span class="string">'%s'</span> % round(y, <span class="number">1</span>), ha=<span class="string">'center'</span>, color=colors1)</span><br><span class="line"></span><br><span class="line">    pl.xticks(rotation=<span class="number">270</span>)  <span class="comment"># x轴名称太长发生重叠，旋转为纵向显示</span></span><br><span class="line">    plt.tight_layout()  <span class="comment"># 自动控制空白边缘，以全部显示x轴名称</span></span><br><span class="line">    <span class="comment"># plt.savefig('电影评分最高top10.png')   #保存图片</span></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ------------------------------</span></span><br><span class="line"><span class="comment"># 2各国家的电影数量比较</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">annalysis_2</span><span class="params">()</span>:</span></span><br><span class="line">    area_count = df.groupby(</span><br><span class="line">        by=<span class="string">'area'</span>).area.count().sort_values(ascending=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘图方法1</span></span><br><span class="line">    area_count.plot.bar(color=<span class="string">'#4652B1'</span>)  <span class="comment"># 设置为蓝紫色</span></span><br><span class="line">    pl.xticks(rotation=<span class="number">0</span>)  <span class="comment"># x轴名称太长重叠，旋转为纵向</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘图方法2</span></span><br><span class="line">    <span class="comment"># plt.bar(range(11),area_count.values,tick_label = area_count.index,color</span></span><br><span class="line">    <span class="comment"># = '#4652B1')</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> enumerate(list(area_count.values)):</span><br><span class="line">        plt.text(x, y + <span class="number">0.5</span>, <span class="string">'%s'</span> % round(y, <span class="number">1</span>), ha=<span class="string">'center'</span>, color=colors1)</span><br><span class="line">    plt.title(<span class="string">'各国/地区电影数量排名'</span>, color=colors1)</span><br><span class="line">    plt.xlabel(<span class="string">'国家/地区'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'数量(部)'</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"><span class="comment"># plt.savefig('各国(地区)电影数量排名.png')</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ------------------------------</span></span><br><span class="line"><span class="comment"># 3电影作品数量集中的年份</span></span><br><span class="line"><span class="comment"># 从日期中提取年份</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">annalysis_3</span><span class="params">()</span>:</span></span><br><span class="line">    df[<span class="string">'year'</span>] = df[<span class="string">'time'</span>].map(<span class="keyword">lambda</span> x: x.split(<span class="string">'/'</span>)[<span class="number">0</span>])</span><br><span class="line">    <span class="comment"># print(df.info())</span></span><br><span class="line">    <span class="comment"># print(df.head())</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 统计各年上映的电影数量</span></span><br><span class="line">    grouped_year = df.groupby(<span class="string">'year'</span>)</span><br><span class="line">    grouped_year_amount = grouped_year.year.count()</span><br><span class="line">    top_year = grouped_year_amount.sort_values(ascending=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘图</span></span><br><span class="line">    top_year.plot(kind=<span class="string">'bar'</span>, color=<span class="string">'orangered'</span>)  <span class="comment"># 颜色设置为橙红色</span></span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> enumerate(list(top_year.values)):</span><br><span class="line">        plt.text(x, y + <span class="number">0.1</span>, <span class="string">'%s'</span> % round(y, <span class="number">1</span>), ha=<span class="string">'center'</span>, color=colors1)</span><br><span class="line">    plt.title(<span class="string">'电影数量年份排名'</span>, color=colors1)</span><br><span class="line">    plt.xlabel(<span class="string">'年份(年)'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'数量(部)'</span>)</span><br><span class="line"></span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    <span class="comment"># plt.savefig('电影数量年份排名.png')</span></span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ------------------------------</span></span><br><span class="line"><span class="comment"># 4拥有电影作品数量最多的演员</span></span><br><span class="line"><span class="comment"># 表中的演员位于同一列，用逗号分割符隔开。需进行分割然后全部提取到list中</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">annalysis_4</span><span class="params">()</span>:</span></span><br><span class="line">    starlist = []</span><br><span class="line">    star_total = df.star</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> df.star.str.replace(<span class="string">' '</span>, <span class="string">''</span>).str.split(<span class="string">','</span>):</span><br><span class="line">        starlist.extend(i)</span><br><span class="line">    <span class="comment"># print(starlist)</span></span><br><span class="line">    <span class="comment"># print(len(starlist))</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># set去除重复的演员名</span></span><br><span class="line">    starall = set(starlist)</span><br><span class="line">    <span class="comment"># print(starall)</span></span><br><span class="line">    <span class="comment"># print(len(starall))</span></span><br><span class="line"></span><br><span class="line">    starall2 = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> starall:</span><br><span class="line">        <span class="keyword">if</span> starlist.count(i) &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="comment"># 筛选出电影数量超过1部的演员</span></span><br><span class="line">            starall2[i] = starlist.count(i)</span><br><span class="line"></span><br><span class="line">    starall2 = sorted(starall2.items(),</span><br><span class="line">                      key=<span class="keyword">lambda</span> starlist: starlist[<span class="number">1</span>], reverse=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    starall2 = dict(starall2[:<span class="number">10</span>])  <span class="comment"># 将元组转为字典格式</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘图</span></span><br><span class="line">    x_star = list(starall2.keys())  <span class="comment"># x轴坐标</span></span><br><span class="line">    y_star = list(starall2.values())  <span class="comment"># y轴坐标</span></span><br><span class="line"></span><br><span class="line">    plt.bar(range(<span class="number">10</span>), y_star, tick_label=x_star)</span><br><span class="line">    pl.xticks(rotation=<span class="number">270</span>)</span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> enumerate(y_star):</span><br><span class="line">        plt.text(x, y + <span class="number">0.1</span>, <span class="string">'%s'</span> % round(y, <span class="number">1</span>), ha=<span class="string">'center'</span>, color=colors1)</span><br><span class="line"></span><br><span class="line">    plt.title(<span class="string">'演员电影作品数量排名'</span>, color=colors1)</span><br><span class="line">    plt.xlabel(<span class="string">'演员'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'数量(部)'</span>)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.show()</span><br><span class="line"><span class="comment"># plt.savefig('演员电影作品数量排名.png')</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    annalysis_1()</span><br><span class="line">    annalysis_2()</span><br><span class="line">    annalysis_3()</span><br><span class="line">    annalysis_4()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure></p>

      
    </div>
	
	
    
    
    
	

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>你一打赏，我就写得更来劲了</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.png" alt="高级农民工 微信支付"/>
        <p>微信支付</p>
      </div>
    

    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/python爬虫/" rel="tag"><i class="fa fa-tag"></i> python爬虫</a>
          
            <a href="/tags/requests/" rel="tag"><i class="fa fa-tag"></i> requests</a>
          
            <a href="/tags/正则表达式/" rel="tag"><i class="fa fa-tag"></i> 正则表达式</a>
          
            <a href="/tags/beautifulsoup/" rel="tag"><i class="fa fa-tag"></i> beautifulsoup</a>
          
            <a href="/tags/css/" rel="tag"><i class="fa fa-tag"></i> css</a>
          
            <a href="/tags/xpath/" rel="tag"><i class="fa fa-tag"></i> xpath</a>
          
            <a href="/tags/lxml/" rel="tag"><i class="fa fa-tag"></i> lxml</a>
          
        </div>
      

      
      
        <div class="post-widgets">
        
          <div class="wp_rating">
            <div style="color: rgba(0, 0, 0, 0.75); font-size:13px; letter-spacing:3px">(&gt;你觉得这篇文章怎么样？&lt;)</div>
            <div id="wpac-rating"></div>
          </div>
        

        

        
        </div>
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/web_scraping_withpython2.html" rel="prev" title="python爬虫：表格型数据抓取">
                <i class="fa fa-chevron-left"></i> python爬虫：表格型数据抓取
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/hexo02.html" rel="next" title="4块钱,用Github+Hexo搭建你的个人博客：美化篇">
                4块钱,用Github+Hexo搭建你的个人博客：美化篇 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="http://pbscl931v.bkt.clouddn.com/18-8-3/40685653.jpg"
                alt="高级农民工" />
            
              <p class="site-author-name" itemprop="name">高级农民工</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/makcyun" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:johnny824lee@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          
        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-为什么爬取该网页？"><span class="nav-text">1. 为什么爬取该网页？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-爬虫目标"><span class="nav-text">2. 爬虫目标</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-爬取步骤"><span class="nav-text">3. 爬取步骤</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-网址URL分析"><span class="nav-text">3.1. 网址URL分析</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-Requests获取首页数据"><span class="nav-text">3.2. Requests获取首页数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-4种内容解析提取方法"><span class="nav-text">3.3. 4种内容解析提取方法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3-1-正则表达式提取"><span class="nav-text">3.3.1. 正则表达式提取</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3-2-lxml结合xpath提取"><span class="nav-text">3.3.2. lxml结合xpath提取</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3-3-Beautiful-Soup-css选择器"><span class="nav-text">3.3.3. Beautiful Soup + css选择器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3-4-Beautiful-Soup-find-all函数提取"><span class="nav-text">3.3.4. Beautiful Soup + find_all函数提取</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-4-数据存储"><span class="nav-text">3.4. 数据存储</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-5-分页爬取"><span class="nav-text">3.5. 分页爬取</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-可视化分析"><span class="nav-text">4. 可视化分析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-电影评分最高top10"><span class="nav-text">4.1. 电影评分最高top10</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-各国家的电影数量比较"><span class="nav-text">4.2. 各国家的电影数量比较</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-电影作品数量集中的年份"><span class="nav-text">4.3. 电影作品数量集中的年份</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-4-拥有电影作品数量最多的演员"><span class="nav-text">4.4 拥有电影作品数量最多的演员</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-完整程序"><span class="nav-text">5. 完整程序</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love" id="heart">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">高级农民工</span>


  
</div>

# 用<!--注释语句-->
<span id="busuanzi_container_site_uv">
  访客数:<span id="busuanzi_value_site_uv"></span>人次
</span>


  <!--<div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>-->




  <span class="post-meta-divider">|</span>



  <!--<div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>-->






<span id="busuanzi_container_site_pv">
   总访问量:<span id="busuanzi_value_site_pv"></span>次
</span>


  <span class="post-meta-divider">|</span>



<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共19.0k字</span>
</div>


        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("yps9pUuWWGeNG1MwVI2tVGys-gzGzoHsz", "SNn7AhhHPrCndytXWSTwD5A2");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  
  <script type="text/javascript">
  wpac_init = window.wpac_init || [];
  wpac_init.push({widget: 'Rating', id: 12522,
    el: 'wpac-rating',
    color: 'E0943E'
  });
  (function() {
    if ('WIDGETPACK_LOADED' in window) return;
    WIDGETPACK_LOADED = true;
    var mc = document.createElement('script');
    mc.type = 'text/javascript';
    mc.async = true;
    mc.src = '//embed.widgetpack.com/widget.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(mc, s.nextSibling);
  })();
  </script>


  

  

  

  
</body>
</html>
