<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>高级农民工</title>
  
  <subtitle>Beginner&#39;s Mind</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.makcyun.top/"/>
  <updated>2018-08-20T11:17:45.900Z</updated>
  <id>https://www.makcyun.top/</id>
  
  <author>
    <name>高级农民工</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Requests+多种方法爬取猫眼top100电影</title>
    <link href="https://www.makcyun.top/web_scraping_withpython1.html"/>
    <id>https://www.makcyun.top/web_scraping_withpython1.html</id>
    <published>2018-08-20T11:18:14.973Z</published>
    <updated>2018-08-20T11:17:45.900Z</updated>
    
    <content type="html"><![CDATA[<p><b><em>python爬虫第1篇</em></b><br>利用Request请求库和4种内容提取方法：正则表达式、lxml+xpath、Beatutifulsoup+css选择器、Beatutifulsoup+find_all爬取网页内容。</p><a id="more"></a>  <p><strong>摘要：</strong> 作为小白，<strong>爬虫可以说是入门python最快和最容易获得成就感的途径</strong>。因为初级爬虫的套路相对固定，常见的方法只有几种，比较好上手。最近，跟着崔庆才大佬的书：<em>python3网络爬虫开发实战</em> 学习爬虫。选取网页结构较为简单的猫眼top100电影为案例进行练习。 <strong>重点是用上述所说的4种方法提取出关键内容</strong>。一个问题采用不同的解决方法有助于拓展思维，通过不断练习就能够灵活运用。</p><blockquote><p><strong>本文知识点：</strong><br>Requsts 请求库的使用<br>beautiful+lxml两大解析库使用<br>正则表达式 、xpath、css选择器的使用  </p></blockquote><p><img src="http://pbscl931v.bkt.clouddn.com/18-8-19/49818413.jpg" alt=""></p><h2 id="1-为什么爬取该网页？"><a href="#1-为什么爬取该网页？" class="headerlink" title="1. 为什么爬取该网页？"></a>1. 为什么爬取该网页？</h2><ul><li>比较懒，不想一页页地去翻100部电影的介绍，<strong>想在一个页面内进行总体浏览</strong>（比如在excel表格中）；</li></ul><p><img src="http://pbscl931v.bkt.clouddn.com/18-8-19/28479553.jpg" alt=""></p><ul><li>想<strong>深入了解一些比较有意思的信息</strong>，比如：哪部电影的评分最高？哪位演员的作品数量最多？哪个国家/地区上榜的电影数量最多？哪一年上榜的电影作品最多等。这些信息在网页上是不那么容易能直接获得的，所以需要爬虫。<br><img src="http://pbscl931v.bkt.clouddn.com/18-8-20/66062822.jpg" alt=""></li></ul><h2 id="2-爬虫目标"><a href="#2-爬虫目标" class="headerlink" title="2. 爬虫目标"></a>2. 爬虫目标</h2><ul><li>从网页中提取出top100电影的电影名称、封面图片、排名、评分、演员、上映国家/地区、评分等信息，并保存为csv文本文件。</li><li>根据爬取结果，进行简单的可视化分析。</li></ul><p>平台：windows7 + SublimeText3</p><h2 id="3-爬取步骤"><a href="#3-爬取步骤" class="headerlink" title="3. 爬取步骤"></a>3. 爬取步骤</h2><h3 id="3-1-网址URL分析"><a href="#3-1-网址URL分析" class="headerlink" title="3.1. 网址URL分析"></a>3.1. 网址URL分析</h3><p>首先，打开猫眼Top100的url网址： <a href="http://maoyan.com/board/4?offset=0" target="_blank" rel="noopener"><strong>http://maoyan.com/board/4?offset=0</strong></a>。页面非常简单，所包含的信息就是上述所说的爬虫目标。下拉页面到底部，点击第2页可以看到网址变为：<strong><a href="http://maoyan.com/board/4?offset=10" target="_blank" rel="noopener">http://maoyan.com/board/4?offset=10</a></strong>。因此，可以推断出url的变化规律：offset表示偏移，10代表一个页面的电影偏移数量，即：第一页电影是从0-10，第二页电影是从11-20。因此，获取全部100部电影，只需要构造出10个url，然后依次获取网页内容，再用不同的方法提取出所需内容就可以了。<br>下面，用requests方法获取第一个页面。</p><h3 id="3-2-Requests获取首页数据"><a href="#3-2-Requests获取首页数据" class="headerlink" title="3.2. Requests获取首页数据"></a>3.2. Requests获取首页数据</h3><p>先定义一个获取单个页面的函数：get_one_page()，传入url参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_one_page</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        headers = &#123;</span><br><span class="line">            <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'</span>&#125;</span><br><span class="line">        <span class="comment"># 不加headers爬不了</span></span><br><span class="line">        response = requests.get(url, headers=headers)</span><br><span class="line">        <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> response.text</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line">    <span class="keyword">except</span> RequestException:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line">    <span class="comment"># try-except语句捕获异常</span></span><br></pre></td></tr></table></figure><p>接下来在main()函数中设置url。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    url = <span class="string">'http://maoyan.com/board/4?offset=0'</span></span><br><span class="line">    html = get_one_page(url)</span><br><span class="line">    print(html)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p>运行上述程序后，首页的源代码就被爬取下来了。如下图所示：</p><p><img src="http://pbscl931v.bkt.clouddn.com/18-8-19/18415362.jpg" alt=""></p><p>接下来就需要从整个网页中提取出几项我们需要的内容，用到的方法就是上述所说的四种方法，下面分别进行说明。</p><h3 id="3-3-4种内容解析提取方法"><a href="#3-3-4种内容解析提取方法" class="headerlink" title="3.3. 4种内容解析提取方法"></a>3.3. 4种内容解析提取方法</h3><h4 id="3-3-1-正则表达式提取"><a href="#3-3-1-正则表达式提取" class="headerlink" title="3.3.1. 正则表达式提取"></a>3.3.1. 正则表达式提取</h4><p>第一种是利用<strong>正则表达式</strong>提取。<br>什么是正则表达式？ 下面这串看起来乱七八糟的符号就是正则表达式的语法。</p><figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">'<span class="doctag">&lt;dd&gt;</span>.*?board-index.*?&gt;(\d+)<span class="doctag">&lt;/i&gt;</span>.*?data-src="(.*?)".*?name"&gt;<span class="doctag">&lt;a.*?&gt;</span>(.*?)<span class="doctag">&lt;/a&gt;</span>.*?'</span></span><br></pre></td></tr></table></figure><p>它是一种强大的字符串处理工具。之所以叫正则表达式，是因为它们可以识别正则字符串（regular string）。可以这么定义：“ 如果你给我的字符串符合规则，我就返回它”；“如果字符串不符合规则，我就忽略它”。通过requests抓取下来的网页是一堆大量的字符串，用它处理后便可提取出我们想要的内容。</p><p>如果还不了解它，可以参考下面的教程：</p><blockquote><p><a href="http://www.runoob.com/regexp/regexp-syntax.html" target="_blank" rel="noopener">http://www.runoob.com/regexp/regexp-syntax.html</a><br><a href="https://www.w3cschool.cn/regexp/zoxa1pq7.html" target="_blank" rel="noopener">https://www.w3cschool.cn/regexp/zoxa1pq7.html</a></p></blockquote><p><strong>正则表达式常用语法：</strong></p><style>table th:nth-of-type(1) {    width: 60px;}</style><table><thead><tr><th style="text-align:center">模式</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center">\w</td><td style="text-align:center">匹配字母数字及下划线</td></tr><tr><td style="text-align:center">\W</td><td style="text-align:center">匹配非字母数字及下划线</td></tr><tr><td style="text-align:center">\s</td><td style="text-align:center">匹配任意空白字符，等价于 [\t\n\r\f]</td></tr><tr><td style="text-align:center">\S</td><td style="text-align:center">匹配任意非空字符</td></tr><tr><td style="text-align:center">\d</td><td style="text-align:center">匹配任意数字，等价于 [0-9]</td></tr><tr><td style="text-align:center">\D</td><td style="text-align:center">匹配任意非数字</td></tr><tr><td style="text-align:center">\n</td><td style="text-align:center">匹配一个换行符</td></tr><tr><td style="text-align:center">\t</td><td style="text-align:center">匹配一个制表符</td></tr><tr><td style="text-align:center">^</td><td style="text-align:center">匹配字符串开始位置的字符</td></tr><tr><td style="text-align:center">$</td><td style="text-align:center">匹配字符串的末尾</td></tr><tr><td style="text-align:center">.</td><td style="text-align:center">匹配任意字符，除了换行符</td></tr><tr><td style="text-align:center">[…]</td><td style="text-align:center">用来表示一组字符，单独列出：[amk] 匹配 ‘a’，’m’ 或 ‘k’</td></tr><tr><td style="text-align:center">[^…]</td><td style="text-align:center">不在 [ ] 中的字符</td></tr><tr><td style="text-align:center">*</td><td style="text-align:center">匹配前面的字符、子表达式或括号里的字符 0 次或多次</td></tr><tr><td style="text-align:center">+</td><td style="text-align:center">同上，匹配至少一次</td></tr><tr><td style="text-align:center">?</td><td style="text-align:center">同上，匹配0到1次</td></tr><tr><td style="text-align:center">{n}</td><td style="text-align:center">匹配前面的字符、子表达式或括号里的字符 n 次</td></tr><tr><td style="text-align:center">{n, m}</td><td style="text-align:center">同上，匹配 m 到n 次（包含 m 或 n）</td></tr><tr><td style="text-align:center">( )</td><td style="text-align:center">匹配括号内的表达式，也表示一个组</td></tr></tbody></table><p>下面，开始提取关键内容。右键网页-检查-Network选项，选中左边第一个文件然后定位到电影信息的相应位置，如下图：</p><p><img src="http://pbscl931v.bkt.clouddn.com/18-8-19/84055565.jpg" alt=""></p><p>可以看到每部电影的相关信息都在<strong>dd</strong>这个节点之中。所以就可以从该节点运用正则进行提取。<br>第1个要提取的内容是电影的排名。它位于class=”board-index”的<strong>i</strong>节点内。不需要提取的内容用’.*?’替代，需要提取的数字排名用（）括起来，（）里面的数字表示为（\d+）。正则表达式可以写为：</p><figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">'<span class="doctag">&lt;dd&gt;</span>.*?board-index.*?&gt;(\d+)<span class="doctag">&lt;/i&gt;</span>'</span></span><br></pre></td></tr></table></figure><p>接着，第2个需要提取的是封面图片，图片网址位于img节点的’data-src’属性中，正则表达式可写为：</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">'<span class="class"><span class="keyword">data</span>-src="(.*?)".*?'</span></span><br></pre></td></tr></table></figure><p>第1和第2个正则之间的代码是不需要的，用’.*?’替代，所以这两部分合起来写就是：</p><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">'<span class="variable">&lt;dd&gt;</span>.<span class="symbol">*</span>?board-index.<span class="symbol">*</span>?&gt;(\d+)<span class="variable">&lt;/i&gt;</span>.<span class="symbol">*</span>?data-src=<span class="string">"(.*?)"</span></span><br></pre></td></tr></table></figure><p>同理，可以依次用正则写下主演、上映时间和评分等内容,完整的正则表达式如下：</p><figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">'<span class="doctag">&lt;dd&gt;</span>.*?board-index.*?&gt;(\d+)<span class="doctag">&lt;/i&gt;</span>.*?data-src="(.*?)".*?name"&gt;<span class="doctag">&lt;a.*?&gt;</span>(.*?)<span class="doctag">&lt;/a&gt;</span>.*?star"&gt;(.*?)<span class="doctag">&lt;/p&gt;</span>.*?releasetime"&gt;(.*?)<span class="doctag">&lt;/p.*?integer"&gt;</span>(.*?)<span class="doctag">&lt;/i&gt;</span>.*?fraction"&gt;(.*?)<span class="doctag">&lt;/i&gt;</span>.*?<span class="doctag">&lt;/dd&gt;</span>'</span></span><br></pre></td></tr></table></figure><p>正则表达式写好以后，可以定义一个页面解析提取方法：parse_one_page（），用来提取内容：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_one_page</span><span class="params">(html)</span>:</span></span><br><span class="line">    pattern = re.compile(</span><br><span class="line">        <span class="string">'&lt;dd&gt;.*?board-index.*?&gt;(\d+)&lt;/i&gt;.*?data-src="(.*?)".*?name"&gt;&lt;a.*?&gt;(.*?)&lt;/a&gt;.*?star"&gt;(.*?)&lt;/p&gt;.*?releasetime"&gt;(.*?)&lt;/p.*?integer"&gt;(.*?)&lt;/i&gt;.*?fraction"&gt;(.*?)&lt;/i&gt;.*?&lt;/dd&gt;'</span>, re.S)</span><br><span class="line">    <span class="comment"># re.S表示匹配任意字符，如果不加，则无法匹配换行符</span></span><br><span class="line">    items = re.findall(pattern, html)</span><br><span class="line">    <span class="comment"># print(items)</span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="string">'index'</span>: item[<span class="number">0</span>],</span><br><span class="line">            <span class="string">'thumb'</span>: get_thumb(item[<span class="number">1</span>]),  <span class="comment"># 定义get_thumb()方法进一步处理网址</span></span><br><span class="line">            <span class="string">'name'</span>: item[<span class="number">2</span>],</span><br><span class="line">            <span class="string">'star'</span>: item[<span class="number">3</span>].strip()[<span class="number">3</span>:],</span><br><span class="line">            <span class="comment"># 'time': item[4].strip()[5:],</span></span><br><span class="line">            <span class="comment"># 用两个方法分别提取time里的日期和地区</span></span><br><span class="line">            <span class="string">'time'</span>: get_release_time(item[<span class="number">4</span>].strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'area'</span>: get_release_area(item[<span class="number">4</span>].strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'score'</span>: item[<span class="number">5</span>].strip() + item[<span class="number">6</span>].strip()</span><br><span class="line">            <span class="comment"># 评分score由整数+小数两部分组成</span></span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><blockquote><p><strong>Tips:</strong><br><strong>re.S:</strong>匹配任意字符，如果不加，则无法匹配换行符；<br><strong>yield:</strong>使用yield的好处是作为生成器，可以遍历迭代，并且将数据整理形成字典，输出结果美观。具体用法可参考：<a href="https://blog.csdn.net/zhangpinghao/article/details/18716275；" target="_blank" rel="noopener">https://blog.csdn.net/zhangpinghao/article/details/18716275；</a><br><strong>.strip():</strong>用于去掉字符串中的空格。</p></blockquote><p>上面程序为了便于提取内容，又定义了3个方法：get_thumb（）、get_release_time（）和 get_release_area（）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取封面大图</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_thumb</span><span class="params">(url)</span>:</span></span><br><span class="line">    pattern = re.compile(<span class="string">r'(.*?)@.*?'</span>)</span><br><span class="line">    thumb = re.search(pattern, url)</span><br><span class="line">    <span class="keyword">return</span> thumb.group(<span class="number">1</span>)</span><br><span class="line"><span class="comment"># http://p0.meituan.net/movie/5420be40e3b755ffe04779b9b199e935256906.jpg@160w_220h_1e_1c</span></span><br><span class="line"><span class="comment"># 去掉@160w_220h_1e_1c就是大图    </span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取上映时间函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_release_time</span><span class="params">(data)</span>:</span></span><br><span class="line">    pattern = re.compile(<span class="string">r'(.*?)(\(|$)'</span>)</span><br><span class="line">    items = re.search(pattern, data)</span><br><span class="line">    <span class="keyword">if</span> items <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'未知'</span></span><br><span class="line">    <span class="keyword">return</span> items.group(<span class="number">1</span>)  <span class="comment"># 返回匹配到的第一个括号(.*?)中结果即时间</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取国家/地区函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_release_area</span><span class="params">(data)</span>:</span></span><br><span class="line">    pattern = re.compile(<span class="string">r'.*\((.*)\)'</span>)</span><br><span class="line">    <span class="comment"># $表示匹配一行字符串的结尾，这里就是(.*?)；\(|$,表示匹配字符串含有(,或者只有(.*?)</span></span><br><span class="line">    items = re.search(pattern, data)</span><br><span class="line">    <span class="keyword">if</span> items <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'未知'</span></span><br><span class="line">    <span class="keyword">return</span> items.group(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><blockquote><p><strong>Tips:</strong><br><strong>‘r’：</strong>正则前面加上’r’ 是为了告诉编译器这个string是个raw string，不要转意’\’。当一个字符串使用了正则表达式后，最好在前面加上’r’；<br><strong>‘|’ ‘$’：</strong>  正则’|’表示或’，’$’表示匹配一行字符串的结尾；<br><strong>.group(1)</strong>：意思是返回search匹配的第一个括号中的结果，即(.*?)，gropup()则返回所有结果2013-12-18(，group(1)返回’（’。</p></blockquote><p>接下来，修改main()函数来输出爬取的内容：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    url = <span class="string">'http://maoyan.com/board/4?offset=0'</span></span><br><span class="line">    html = get_one_page(url)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> parse_one_page(html):  </span><br><span class="line">        print(item)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><blockquote><p><strong>Tips:</strong><br><strong>if <strong> name</strong> == ‘_ _main__’:</strong>当.py文件被直接运行时，if <strong> name</strong> == ‘_ <em>main__’之下的代码块将被运行；当.py文件以模块形式被导入时，if <strong> name</strong> == ‘</em> _main__’之下的代码块不被运行。<br>参考：<a href="https://blog.csdn.net/yjk13703623757/article/details/77918633。" target="_blank" rel="noopener">https://blog.csdn.net/yjk13703623757/article/details/77918633。</a></p></blockquote><p>运行程序，就可成功地提取出所需内容，结果如下：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">'index'</span>: <span class="string">'1'</span>, <span class="string">'thumb'</span>: <span class="string">'http://p1.meituan.net/movie/20803f59291c47e1e116c11963ce019e68711.jpg'</span>, <span class="string">'name'</span>: <span class="string">'霸王别姬'</span>, <span class="string">'star'</span>: <span class="string">'张国荣,张丰毅,巩俐'</span>, <span class="string">'time'</span>: <span class="string">'1993-01-01'</span>, <span class="string">'area'</span>: <span class="string">'中国香港'</span>, <span class="string">'score'</span>: <span class="string">'9.6'</span>&#125;</span><br><span class="line">&#123;<span class="string">'index'</span>: <span class="string">'2'</span>, <span class="string">'thumb'</span>: <span class="string">'http://p0.meituan.net/movie/54617769d96807e4d81804284ffe2a27239007.jpg'</span>, <span class="string">'name'</span>: <span class="string">'罗马假日'</span>, <span class="string">'star'</span>: <span class="string">'格利高里·派克,奥黛丽·赫本,埃迪·艾伯特'</span>, <span class="string">'time'</span>: <span class="string">'1953-09-02'</span>, <span class="string">'area'</span>: <span class="string">'美国'</span>, <span class="string">'score'</span>: <span class="string">'9.1'</span>&#125;</span><br><span class="line">&#123;<span class="string">'index'</span>: <span class="string">'3'</span>, <span class="string">'thumb'</span>: <span class="string">'http://p0.meituan.net/movie/283292171619cdfd5b240c8fd093f1eb255670.jpg'</span>, <span class="string">'name'</span>: <span class="string">'肖申克的救赎'</span>, <span class="string">'star'</span>: <span class="string">'蒂姆·罗宾斯,摩根·弗里曼,鲍勃·冈顿'</span>, <span class="string">'time'</span>: <span class="string">'1994-10-14'</span>, <span class="string">'area'</span>: <span class="string">'美国'</span>, <span class="string">'score'</span>: <span class="string">'9.5'</span>&#125;</span><br><span class="line">&#123;<span class="string">'index'</span>: <span class="string">'4'</span>, <span class="string">'thumb'</span>: <span class="string">'http://p0.meituan.net/movie/e55ec5d18ccc83ba7db68caae54f165f95924.jpg'</span>, <span class="string">'name'</span>: <span class="string">'这个杀手不太冷'</span>, <span class="string">'star'</span>: <span class="string">'让·雷诺,加里·奥德曼,娜塔莉·波特曼'</span>, <span class="string">'time'</span>: <span class="string">'1994-09-14'</span>, <span class="string">'area'</span>: <span class="string">'法国'</span>, <span class="string">'score'</span>: <span class="string">'9.5'</span>&#125;</span><br><span class="line">&#123;<span class="string">'index'</span>: <span class="string">'5'</span>, <span class="string">'thumb'</span>: <span class="string">'http://p1.meituan.net/movie/f5a924f362f050881f2b8f82e852747c118515.jpg'</span>, <span class="string">'name'</span>: <span class="string">'教父'</span>, <span class="string">'star'</span>: <span class="string">'马龙·白兰度,阿尔·帕西诺,詹姆斯·肯恩'</span>, <span class="string">'time'</span>: <span class="string">'1972-03-24'</span>, <span class="string">'area'</span>: <span class="string">'美国'</span>, <span class="string">'score'</span>: <span class="string">'9.3'</span>&#125;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">&#125;</span><br><span class="line">[Finished <span class="keyword">in</span> <span class="number">1.9</span>s]</span><br></pre></td></tr></table></figure><p>以上是第1种提取方法，如果还不习惯正则表达式这种复杂的语法，可以试试下面的第2种方法。</p><h4 id="3-3-2-lxml结合xpath提取"><a href="#3-3-2-lxml结合xpath提取" class="headerlink" title="3.3.2. lxml结合xpath提取"></a>3.3.2. lxml结合xpath提取</h4><p>该方法需要用到<strong>lxml</strong>这款解析利器，同时搭配xpath语法，利用它的的路径选择表达式，来高效提取所需内容。lxml包为第三方包，需要自行安装。如果对xpath的语法还不太熟悉，可参考下面的教程：<br><a href="http://www.w3school.com.cn/xpath/xpath_syntax.asp" target="_blank" rel="noopener">http://www.w3school.com.cn/xpath/xpath_syntax.asp</a></p><p><strong>xpath常用的规则</strong>    </p><table><thead><tr><th style="text-align:center">表达式</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center">nodename</td><td style="text-align:center">选取此节点的所有子节点</td></tr><tr><td style="text-align:center">/</td><td style="text-align:center">从当前节点选取直接子节点</td></tr><tr><td style="text-align:center">//</td><td style="text-align:center">从当前节点选取子孙节点</td></tr><tr><td style="text-align:center">.</td><td style="text-align:center">选取当前节点</td></tr><tr><td style="text-align:center">..</td><td style="text-align:center">选取当前节点的父节点</td></tr><tr><td style="text-align:center">@</td><td style="text-align:center">选取属性</td></tr></tbody></table><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"container"</span> <span class="attr">id</span>=<span class="string">"app"</span> <span class="attr">class</span>=<span class="string">"page-board/index"</span> &gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"content"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"wrapper"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"main"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"update-time"</span>&gt;</span>2018-08-18<span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"has-fresh-text"</span>&gt;</span>已更新<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"board-content"</span>&gt;</span>榜单规则：将猫眼电影库中的经典影片，按照评分和评分人数从高到低综合排序取前100名，每天上午10点更新。相关数据来源于“猫眼电影库”。<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">dl</span> <span class="attr">class</span>=<span class="string">"board-wrapper"</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">dd</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">"board-index board-index-1"</span>&gt;</span>1<span class="tag">&lt;/<span class="name">i</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"/films/1203"</span> <span class="attr">title</span>=<span class="string">"霸王别姬"</span> <span class="attr">class</span>=<span class="string">"image-link"</span> <span class="attr">data-act</span>=<span class="string">"boarditem-click"</span> <span class="attr">data-val</span>=<span class="string">"&#123;movieId:1203&#125;"</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">"//ms0.meituan.net/mywww/image/loading_2.e3d934bf.png"</span> <span class="attr">alt</span>=<span class="string">""</span> <span class="attr">class</span>=<span class="string">"poster-default"</span> /&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">img</span> <span class="attr">data-src</span>=<span class="string">"http://p1.meituan.net/movie/20803f59291c47e1e116c11963ce019e68711.jpg@160w_220h_1e_1c"</span> <span class="attr">alt</span>=<span class="string">"霸王别姬"</span> <span class="attr">class</span>=<span class="string">"board-img"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"board-item-main"</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"board-item-content"</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"movie-item-info"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"name"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"/films/1203"</span> <span class="attr">title</span>=<span class="string">"霸王别姬"</span> <span class="attr">data-act</span>=<span class="string">"boarditem-click"</span> <span class="attr">data-val</span>=<span class="string">"&#123;movieId:1203&#125;"</span>&gt;</span>霸王别姬<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"star"</span>&gt;</span></span><br><span class="line">                主演：张国荣,张丰毅,巩俐</span><br><span class="line">        <span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"releasetime"</span>&gt;</span>上映时间：1993-01-01(中国香港)<span class="tag">&lt;/<span class="name">p</span>&gt;</span>    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"movie-item-number score-num"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"score"</span>&gt;</span><span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">"integer"</span>&gt;</span>9.<span class="tag">&lt;/<span class="name">i</span>&gt;</span><span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">"fraction"</span>&gt;</span>6<span class="tag">&lt;/<span class="name">i</span>&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span>        </span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line">      <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line">                <span class="tag">&lt;/<span class="name">dd</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">dd</span>&gt;</span></span><br></pre></td></tr></table></figure><p>根据截取的部分html网页，先来提取第1个电影排名信息，有两种方法。<br><strong>第一种：</strong>直接复制。<br>右键-Copy-Copy Xpath，得到xpath路径为：<strong>//*[@id=”app”]/div/div/div[1]/dl/dd[1]/i</strong>,为了能够提取到页面所有的排名信息，需进一步修改为：<strong>//*[@id=”app”]/div/div/div[1]/dl/dd/i/text()</strong>，如果想要再精简一点，可以省去中间部分绝对路径’/‘然后用相对路径’//‘代替，最后进一步修改为：<strong>//*[@id=”app”]//div//dd/i/text()</strong>。<br><img src="http://pbscl931v.bkt.clouddn.com/18-8-19/840042.jpg" alt=""></p><p><strong>第二种：</strong>观察网页结构自己写。<br>首先注意到<strong>id = app</strong>的div节点，因为在整个网页结构id是唯一的不会有第二个相同的，所有可以将该div节点作为xpath语法的起点，然后往下观察分别是3级div节点，可以省略写为：<strong>//div</strong>,再往下分别是是两个并列的<strong>p</strong>节点、<strong>dl</strong>节点、<strong>dd</strong>节点和最后的<strong>i</strong>节点文本。中间可以随意省略，只要保证该路径能够选择到唯一的文本值<strong>‘1’</strong>即可，例如省去p和dl节点，只保留后面的节点。这样，完整路径可以为：<strong>//*[@id=”app”]//div//dd/i/text()</strong>，和上式一样。</p><p><img src="http://pbscl931v.bkt.clouddn.com/18-8-19/87341266.jpg" alt=""></p><p>根据上述思路，可以写下其他内容的xpath路径。观察到路径的前一部分：<strong>//*[@id=”app”]//div//dd</strong>都是一样的，从后面才开始不同，因此为了能够精简代码，将前部分路径赋值为一个变量items，最终提取的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 2 用lxml结合xpath提取内容</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_one_page2</span><span class="params">(html)</span>:</span></span><br><span class="line">    parse = etree.HTML(html)</span><br><span class="line">    items = parse.xpath(<span class="string">'//*[@id="app"]//div//dd'</span>)</span><br><span class="line">    <span class="comment"># 完整的是//*[@id="app"]/div/div/div[1]/dl/dd</span></span><br><span class="line">    <span class="comment"># print(type(items))</span></span><br><span class="line">    <span class="comment"># *代表匹配所有节点，@表示属性</span></span><br><span class="line">    <span class="comment"># 第一个电影是dd[1],要提取页面所有电影则去掉[1]</span></span><br><span class="line">    <span class="comment"># xpath://*[@id="app"]/div/div/div[1]/dl/dd[1]    </span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        <span class="keyword">yield</span>&#123;</span><br><span class="line">            <span class="string">'index'</span>: item.xpath(<span class="string">'./i/text()'</span>)[<span class="number">0</span>],</span><br><span class="line">            <span class="comment">#./i/text()前面的点表示从items节点开始</span></span><br><span class="line">            <span class="comment">#/text()提取文本</span></span><br><span class="line">            <span class="string">'thumb'</span>: get_thumb(str(item.xpath(<span class="string">'./a/img[2]/@data-src'</span>)[<span class="number">0</span>].strip())),</span><br><span class="line">            <span class="comment"># 'thumb': 要在network中定位，在elements里会写成@src而不是@data-src，从而会报list index out of range错误。</span></span><br><span class="line">            <span class="string">'name'</span>: item.xpath(<span class="string">'./a/@title'</span>)[<span class="number">0</span>],</span><br><span class="line">            <span class="string">'star'</span>: item.xpath(<span class="string">'.//p[@class = "star"]/text()'</span>)[<span class="number">0</span>].strip(),</span><br><span class="line">            <span class="string">'time'</span>: get_release_time(item.xpath(</span><br><span class="line">                <span class="string">'.//p[@class = "releasetime"]/text()'</span>)[<span class="number">0</span>].strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'area'</span>: get_release_area(item.xpath(</span><br><span class="line">                <span class="string">'.//p[@class = "releasetime"]/text()'</span>)[<span class="number">0</span>].strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'score'</span> : item.xpath(<span class="string">'.//p[@class = "score"]/i[1]/text()'</span>)[<span class="number">0</span>] + \</span><br><span class="line">            item.xpath(<span class="string">'.//p[@class = "score"]/i[2]/text()'</span>)[<span class="number">0</span>]</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><blockquote><p><strong>Tips:</strong><br><strong>[0]：</strong>xpath后面添加了[0]是因为返回的是只有1个字符串的list，添加[0]是将list提取为字符串，使其简洁；<br><strong>Network：</strong>要在最原始的Network选项卡中定位，而不是Elements中，不然提取不到相关内容；<br><strong>class属性：</strong>p[@class = “star”]/text()表示提取class属性为”star”的p节点的文本值；<br><strong>提取属性值：</strong>img[2]/@data-src’：提取img节点的data-src属性值，属性值后面无需添加’/text()’</p></blockquote><p>运行程序，就可成功地提取出所需内容，结果和第一种方法一样。</p><p>以上是第2种提取方法，如果也不太习惯xpath语法，可以试试下面的第3种方法。</p><h4 id="3-3-3-Beautiful-Soup-css选择器"><a href="#3-3-3-Beautiful-Soup-css选择器" class="headerlink" title="3.3.3. Beautiful Soup + css选择器"></a>3.3.3. Beautiful Soup + css选择器</h4><p>Beautiful Soup 同lxml一样，是一个非常强大的python解析库，可以从HTML或XML文件中提取效率非常高。关于它的用法，可参考下面的教程：<br><a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/" target="_blank" rel="noopener">https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/</a></p><p>css选择器选是一种模式，用于选择需要添加样式的元素，使用它的语法同样能够快速定位到所需节点，然后提取相应内容。使用方法可参考下面的教程：<br><a href="http://www.w3school.com.cn/cssref/css_selectors.asp" target="_blank" rel="noopener">http://www.w3school.com.cn/cssref/css_selectors.asp</a></p><p><strong>css选择器常用的规则</strong>  </p><style>table th:first-of-type {    width: 120px;}th:nth-of-type(2) {    width: 120px;}</style><table><thead><tr><th style="text-align:center">选择器</th><th style="text-align:center">例子</th><th style="text-align:center">例子描述</th></tr></thead><tbody><tr><td style="text-align:center">.class</td><td style="text-align:center">.intro</td><td style="text-align:center">选择 class=”intro” 的所有元素。</td></tr><tr><td style="text-align:center">#id</td><td style="text-align:center">#firstname</td><td style="text-align:center">选择 id=”firstname” 的所有元素。</td></tr><tr><td style="text-align:center">*</td><td style="text-align:center">*</td><td style="text-align:center">选择所有元素。</td></tr><tr><td style="text-align:center">element</td><td style="text-align:center">p</td><td style="text-align:center">选择所有p元素。</td></tr><tr><td style="text-align:center">element,element</td><td style="text-align:center">div,p</td><td style="text-align:center">选择所有div元素和所有p元素。</td></tr><tr><td style="text-align:center">element?element</td><td style="text-align:center">div p</td><td style="text-align:center">选择div元素内部的所有p元素。</td></tr><tr><td style="text-align:center">element&gt;element</td><td style="text-align:center">div&gt;p</td><td style="text-align:center">选择父元素为div元素的所有p元素。</td></tr><tr><td style="text-align:center">element+element</td><td style="text-align:center">div+p</td><td style="text-align:center">选择紧接在div元素之后的所有p元素。</td></tr><tr><td style="text-align:center">[attribute]</td><td style="text-align:center">[target]</td><td style="text-align:center">选择带有 target 属性所有元素。</td></tr><tr><td style="text-align:center">[attribute=value]</td><td style="text-align:center">[target=_blank]</td><td style="text-align:center">选择 target=”_blank” 的所有元素。</td></tr></tbody></table><p>下面就利用这种方法进行提取：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 3 用beautifulsoup + css选择器提取</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_one_page3</span><span class="params">(html)</span>:</span></span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">'lxml'</span>)</span><br><span class="line">    <span class="comment"># print(content)</span></span><br><span class="line">    <span class="comment"># print(type(content))</span></span><br><span class="line">    <span class="comment"># print('------------')</span></span><br><span class="line">    items = range(<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        <span class="keyword">yield</span>&#123;</span><br><span class="line"></span><br><span class="line">            <span class="string">'index'</span>: soup.select(<span class="string">'dd i.board-index'</span>)[item].string,</span><br><span class="line">            <span class="comment"># iclass节点完整地为'board-index board-index-1',写board-index即可</span></span><br><span class="line">            <span class="string">'thumb'</span>: get_thumb(soup.select(<span class="string">'a &gt; img.board-img'</span>)[item][<span class="string">"data-src"</span>]),</span><br><span class="line">            <span class="comment"># 表示a节点下面的class = board-img的img节点,注意浏览器eelement里面是src节点，而network里面是data-src节点，要用这个才能正确返回值</span></span><br><span class="line"></span><br><span class="line">            <span class="string">'name'</span>: soup.select(<span class="string">'.name a'</span>)[item].string,</span><br><span class="line">            <span class="string">'star'</span>: soup.select(<span class="string">'.star'</span>)[item].string.strip()[<span class="number">3</span>:],</span><br><span class="line">            <span class="string">'time'</span>: get_release_time(soup.select(<span class="string">'.releasetime'</span>)[item].string.strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'area'</span>: get_release_area(soup.select(<span class="string">'.releasetime'</span>)[item].string.strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'score'</span>: soup.select(<span class="string">'.integer'</span>)[item].string + soup.select(<span class="string">'.fraction'</span>)[item].string</span><br><span class="line"></span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure></p><p>运行上述程序，结果同第1种方法一样。</p><h4 id="3-3-4-Beautiful-Soup-find-all函数提取"><a href="#3-3-4-Beautiful-Soup-find-all函数提取" class="headerlink" title="3.3.4. Beautiful Soup + find_all函数提取"></a>3.3.4. Beautiful Soup + find_all函数提取</h4><p>Beautifulsoup除了和css选择器搭配，还可以直接用它自带的find_all函数进行提取。<br><strong>find_all</strong>，顾名思义，就是查询所有符合条件的元素，可以给它传入一些属性或文本来得到符合条件的元素，功能十分强大。<br>它的API如下：</p><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find_all(<span class="name">name</span> , attrs , recursive , text , **kwargs)</span><br></pre></td></tr></table></figure><blockquote><p><strong>常用的语法规则如下：</strong><br>soup.find_all(name=’ul’)： 查找所有<strong>ul</strong>节点，ul节点内还可以嵌套；<br>li.string和li.get_text()：都是获取<strong>li</strong>节点的文本，但推荐使用后者；<br>soup.find_all(attrs={‘id’: ‘list-1’}))：传入 attrs 参数，参数的类型是字典类型，表示查询 <strong>id</strong> 为 <strong>list-1</strong> 的节点；<br>常用的属性比如 id、class 等，可以省略attrs采用更简洁的形式，例如：<br>soup.find_all(id=’list-1’)<br>soup.find_all(class_=’element’)</p></blockquote><p>根据上述常用语法，可以提取网页中所需内容：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_one_page4</span><span class="params">(html)</span>:</span></span><br><span class="line">    soup = BeautifulSoup(html,<span class="string">'lxml'</span>)</span><br><span class="line">    items = range(<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        <span class="keyword">yield</span>&#123;</span><br><span class="line"></span><br><span class="line">            <span class="string">'index'</span>: soup.find_all(class_=<span class="string">'board-index'</span>)[item].string,</span><br><span class="line">            <span class="string">'thumb'</span>: soup.find_all(class_ = <span class="string">'board-img'</span>)[item].attrs[<span class="string">'data-src'</span>],</span><br><span class="line">            <span class="comment"># 用.get('data-src')获取图片src链接，或者用attrs['data-src']</span></span><br><span class="line">            <span class="string">'name'</span>: soup.find_all(name = <span class="string">'p'</span>,attrs = &#123;<span class="string">'class'</span> : <span class="string">'name'</span>&#125;)[item].string,</span><br><span class="line">            <span class="string">'star'</span>: soup.find_all(name = <span class="string">'p'</span>,attrs = &#123;<span class="string">'class'</span>:<span class="string">'star'</span>&#125;)[item].string.strip()[<span class="number">3</span>:],</span><br><span class="line">            <span class="string">'time'</span>: get_release_time(soup.find_all(class_ =<span class="string">'releasetime'</span>)[item].string.strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'area'</span>: get_release_time(soup.find_all(class_ =<span class="string">'releasetime'</span>)[item].string.strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'score'</span>:soup.find_all(name = <span class="string">'i'</span>,attrs = &#123;<span class="string">'class'</span>:<span class="string">'integer'</span>&#125;)[item].string.strip() + soup.find_all(name = <span class="string">'i'</span>,attrs = &#123;<span class="string">'class'</span>:<span class="string">'fraction'</span>&#125;)[item].string.strip()</span><br><span class="line"></span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><p>以上就是4种不同的内容提取方法。</p><h3 id="3-4-数据存储"><a href="#3-4-数据存储" class="headerlink" title="3.4. 数据存储"></a>3.4. 数据存储</h3><p>上述输出的结果为字典格式，可利用csv包的DictWriter函数将字典格式数据存储到csv文件中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据存储到csv</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_to_file3</span><span class="params">(item)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'猫眼top100.csv'</span>, <span class="string">'a'</span>, encoding=<span class="string">'utf_8_sig'</span>,newline=<span class="string">''</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="comment"># 'a'为追加模式（添加）</span></span><br><span class="line">        <span class="comment"># utf_8_sig格式导出csv不乱码 </span></span><br><span class="line">        fieldnames = [<span class="string">'index'</span>, <span class="string">'thumb'</span>, <span class="string">'name'</span>, <span class="string">'star'</span>, <span class="string">'time'</span>, <span class="string">'area'</span>, <span class="string">'score'</span>]</span><br><span class="line">        w = csv.DictWriter(f,fieldnames = fieldnames)</span><br><span class="line">        <span class="comment"># w.writeheader()</span></span><br><span class="line">        w.writerow(item)</span><br></pre></td></tr></table></figure><p>然后修改一下main()方法：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    url = <span class="string">'http://maoyan.com/board/4?offset=0'</span></span><br><span class="line">    html = get_one_page(url)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> parse_one_page(html):  </span><br><span class="line">        <span class="comment"># print(item)</span></span><br><span class="line">        write_to_csv(item)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure></p><p>结果如下图：<br><img src="http://pbscl931v.bkt.clouddn.com/18-8-20/66910595.jpg" alt=""></p><p>再将封面的图片下载下来：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_thumb</span><span class="params">(name, url,num)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = requests.get(url)</span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">'封面图/'</span> + name + <span class="string">'.jpg'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(response.content)</span><br><span class="line">            print(<span class="string">'第%s部电影封面下载完毕'</span> %num)</span><br><span class="line">            print(<span class="string">'------'</span>)</span><br><span class="line">    <span class="keyword">except</span> RequestException <span class="keyword">as</span> e:</span><br><span class="line">        print(e)</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">     <span class="comment"># 不能是w，否则会报错，因为图片是二进制数据所以要用wb</span></span><br></pre></td></tr></table></figure><h3 id="3-5-分页爬取"><a href="#3-5-分页爬取" class="headerlink" title="3.5. 分页爬取"></a>3.5. 分页爬取</h3><p>上面完成了一页电影数据的提取，接下来还需提取剩下9页共90部电影的数据。对网址进行遍历，给网址传入一个offset参数即可，修改如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(offset)</span>:</span></span><br><span class="line">    url = <span class="string">'http://maoyan.com/board/4?offset='</span> + str(offset)</span><br><span class="line">    html = get_one_page(url)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> parse_one_page(html):  </span><br><span class="line">        <span class="comment"># print(item)</span></span><br><span class="line">        write_to_csv(item)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        main(offset = i*<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p>这样就完成了所有电影的爬取。结果如下：</p><p><img src="http://pbscl931v.bkt.clouddn.com/18-8-19/28479553.jpg" alt=""></p><p><img src="http://pbscl931v.bkt.clouddn.com/18-8-19/34117279.jpg" alt=""></p><h2 id="4-可视化分析"><a href="#4-可视化分析" class="headerlink" title="4. 可视化分析"></a>4. 可视化分析</h2><p>俗话说“文不如表，表不如图”。下面根据excel的数据结果，进行简单的数据可视化分析，并用图表呈现。</p><h3 id="4-1-电影评分最高top10"><a href="#4-1-电影评分最高top10" class="headerlink" title="4.1. 电影评分最高top10"></a>4.1. 电影评分最高top10</h3><p>首先，想看一看评分最高的前10部电影是哪些？</p><p>程序如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pylab <span class="keyword">as</span> pl  <span class="comment">#用于修改x轴坐标</span></span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">'ggplot'</span>)   <span class="comment">#默认绘图风格很难看，替换为好看的ggplot风格</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">8</span>,<span class="number">5</span>))   <span class="comment">#设置图片大小</span></span><br><span class="line">colors1 = <span class="string">'#6D6D6D'</span>  <span class="comment">#设置图表title、text标注的颜色</span></span><br><span class="line"></span><br><span class="line">columns = [<span class="string">'index'</span>, <span class="string">'thumb'</span>, <span class="string">'name'</span>, <span class="string">'star'</span>, <span class="string">'time'</span>, <span class="string">'area'</span>, <span class="string">'score'</span>]  <span class="comment">#设置表头</span></span><br><span class="line">df = pd.read_csv(<span class="string">'maoyan_top100.csv'</span>,encoding = <span class="string">"utf-8"</span>,header = <span class="keyword">None</span>,names =columns,index_col = <span class="string">'index'</span>)  <span class="comment">#打开表格</span></span><br><span class="line"><span class="comment"># index_col = 'index' 将索引设为index</span></span><br><span class="line"></span><br><span class="line">df_score = df.sort_values(<span class="string">'score'</span>,ascending = <span class="keyword">False</span>)  <span class="comment">#按得分降序排列</span></span><br><span class="line"></span><br><span class="line">name1 = df_score.name[:<span class="number">10</span>]      <span class="comment">#x轴坐标</span></span><br><span class="line">score1 = df_score.score[:<span class="number">10</span>]    <span class="comment">#y轴坐标  </span></span><br><span class="line">plt.bar(range(<span class="number">10</span>),score1,tick_label = name1)  <span class="comment">#绘制条形图，用range()能搞保持x轴正确顺序</span></span><br><span class="line">plt.ylim ((<span class="number">9</span>,<span class="number">9.8</span>))  <span class="comment">#设置纵坐标轴范围</span></span><br><span class="line">plt.title(<span class="string">'电影评分最高top10'</span>,color = colors1) <span class="comment">#标题</span></span><br><span class="line">plt.xlabel(<span class="string">'电影名称'</span>)      <span class="comment">#x轴标题</span></span><br><span class="line">plt.ylabel(<span class="string">'评分'</span>)          <span class="comment">#y轴标题</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为每个条形图添加数值标签</span></span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> enumerate(list(score1)):</span><br><span class="line">    plt.text(x,y+<span class="number">0.01</span>,<span class="string">'%s'</span> %round(y,<span class="number">1</span>),ha = <span class="string">'center'</span>,color = colors1)</span><br><span class="line"></span><br><span class="line">pl.xticks(rotation=<span class="number">270</span>)   <span class="comment">#x轴名称太长发生重叠，旋转为纵向显示</span></span><br><span class="line">plt.tight_layout()    <span class="comment">#自动控制空白边缘，以全部显示x轴名称</span></span><br><span class="line"><span class="comment"># plt.savefig('电影评分最高top10.png')   #保存图片</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p>结果如下图：<br><img src="http://pbscl931v.bkt.clouddn.com/18-8-20/80083042.jpg" alt=""><br>可以看到：排名最高的分别是两部国产片”霸王别姬”和”大话西游”，其他还包括”肖申克的救赎”、”教父”等。<br>嗯，还好基本上都看过。</p><h3 id="4-2-各国家的电影数量比较"><a href="#4-2-各国家的电影数量比较" class="headerlink" title="4.2. 各国家的电影数量比较"></a>4.2. 各国家的电影数量比较</h3><p>然后，想看看100部电影都是来自哪些国家？<br>程序如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">area_count = df.groupby(by = <span class="string">'area'</span>).area.count().sort_values(ascending = <span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘图方法1</span></span><br><span class="line">area_count.plot.bar(color = <span class="string">'#4652B1'</span>)  <span class="comment">#设置为蓝紫色</span></span><br><span class="line">pl.xticks(rotation=<span class="number">0</span>)   <span class="comment">#x轴名称太长重叠，旋转为纵向</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘图方法2</span></span><br><span class="line"><span class="comment"># plt.bar(range(11),area_count.values,tick_label = area_count.index)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> enumerate(list(area_count.values)):</span><br><span class="line">    plt.text(x,y+<span class="number">0.5</span>,<span class="string">'%s'</span> %round(y,<span class="number">1</span>),ha = <span class="string">'center'</span>,color = colors1)</span><br><span class="line">plt.title(<span class="string">'各国/地区电影数量排名'</span>,color = colors1)</span><br><span class="line">plt.xlabel(<span class="string">'国家/地区'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'数量(部)'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># plt.savefig('各国(地区)电影数量排名.png')</span></span><br></pre></td></tr></table></figure></p><p>结果如下图：<br><img src="http://pbscl931v.bkt.clouddn.com/18-8-20/59456184.jpg" alt=""><br>可以看到，除去网站自身没有显示国家的电影以外，上榜电影被10个国家/地区”承包”了。其中，美国以30部电影的绝对优势占据第1名，其次是8部的日本，韩国第3，居然有7部上榜。<br>不得不说的是香港有5部，而内地一部都没有。。。</p><h3 id="4-3-电影作品数量集中的年份"><a href="#4-3-电影作品数量集中的年份" class="headerlink" title="4.3. 电影作品数量集中的年份"></a>4.3. 电影作品数量集中的年份</h3><p>接下来站在漫长的百年电影史的时间角度上，分析一下哪些年份”贡献了”最多的电影数量，也可以说是”电影大年”。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从日期中提取年份</span></span><br><span class="line">df[<span class="string">'year'</span>] = df[<span class="string">'time'</span>].map(<span class="keyword">lambda</span> x:x.split(<span class="string">'/'</span>)[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># print(df.info())</span></span><br><span class="line"><span class="comment"># print(df.head())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计各年上映的电影数量</span></span><br><span class="line">grouped_year = df.groupby(<span class="string">'year'</span>)</span><br><span class="line">grouped_year_amount = grouped_year.year.count()</span><br><span class="line">top_year = grouped_year_amount.sort_values(ascending = <span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘图</span></span><br><span class="line">top_year.plot(kind = <span class="string">'bar'</span>,color = <span class="string">'orangered'</span>) <span class="comment">#颜色设置为橙红色</span></span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> enumerate(list(top_year.values)):</span><br><span class="line">    plt.text(x,y+<span class="number">0.1</span>,<span class="string">'%s'</span> %round(y,<span class="number">1</span>),ha = <span class="string">'center'</span>,color = colors1)</span><br><span class="line">plt.title(<span class="string">'电影数量年份排名'</span>,color = colors1)</span><br><span class="line">plt.xlabel(<span class="string">'年份(年)'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'数量(部)'</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line"><span class="comment"># plt.savefig('电影数量年份排名.png')</span></span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p>结果如下图：<br><img src="http://pbscl931v.bkt.clouddn.com/18-8-20/32342735.jpg" alt=""><br>可以看到，100部电影来自37个年份。其中2011年上榜电影数量最多，达到9部；其次是前一年的7部。回忆一下，那会儿正是上大学的头两年，可怎么感觉除了阿凡达之外，没有什么其他有印象的电影了。。。<br>另外，网上传的号称”电影史奇迹年”的1994年仅排名第6。这让我进一步对猫眼榜单的权威性产生了质疑。<br>再往后看，发现遥远的1939和1940年也有电影上榜。那会儿应该还是黑白电影时代吧，看来电影的口碑好坏跟外在的技术没有绝对的关系，质量才是王道。</p><h4 id="4-3-1-拥有电影作品数量最多的演员"><a href="#4-3-1-拥有电影作品数量最多的演员" class="headerlink" title="4.3.1. 拥有电影作品数量最多的演员"></a>4.3.1. 拥有电影作品数量最多的演员</h4><p>最后，看看前100部电影中哪些演员的作品数量最多。<br>程序如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#表中的演员位于同一列，用逗号分割符隔开。需进行分割然后全部提取到list中</span></span><br><span class="line">starlist = []</span><br><span class="line">star_total = df.star</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> df.star.str.replace(<span class="string">' '</span>,<span class="string">''</span>).str.split(<span class="string">','</span>):</span><br><span class="line">    starlist.extend(i)  </span><br><span class="line"><span class="comment"># print(starlist)</span></span><br><span class="line"><span class="comment"># print(len(starlist))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># set去除重复的演员名</span></span><br><span class="line">starall = set(starlist)</span><br><span class="line"><span class="comment"># print(starall)</span></span><br><span class="line"><span class="comment"># print(len(starall))</span></span><br><span class="line"></span><br><span class="line">starall2 = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> starall:</span><br><span class="line">    <span class="keyword">if</span> starlist.count(i)&gt;<span class="number">1</span>:</span><br><span class="line">        <span class="comment"># 筛选出电影数量超过1部的演员</span></span><br><span class="line">        starall2[i] = starlist.count(i)</span><br><span class="line"></span><br><span class="line">starall2 = sorted(starall2.items(),key = <span class="keyword">lambda</span> starlist:starlist[<span class="number">1</span>] ,reverse = <span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">starall2 = dict(starall2[:<span class="number">10</span>])  <span class="comment">#将元组转为字典格式</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘图</span></span><br><span class="line">x_star = list(starall2.keys())      <span class="comment">#x轴坐标</span></span><br><span class="line">y_star = list(starall2.values())    <span class="comment">#y轴坐标</span></span><br><span class="line"></span><br><span class="line">plt.bar(range(<span class="number">10</span>),y_star,tick_label = x_star)</span><br><span class="line">pl.xticks(rotation = <span class="number">270</span>)</span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> enumerate(y_star):</span><br><span class="line">    plt.text(x,y+<span class="number">0.1</span>,<span class="string">'%s'</span> %round(y,<span class="number">1</span>),ha = <span class="string">'center'</span>,color = colors1)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">'演员电影作品数量排名'</span>,color = colors1)</span><br><span class="line">plt.xlabel(<span class="string">'演员'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'数量(部)'</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()    </span><br><span class="line"><span class="comment"># plt.savefig('演员电影作品数量排名.png')</span></span><br></pre></td></tr></table></figure></p><p>结果如下图：<br><img src="http://pbscl931v.bkt.clouddn.com/18-8-20/66062822.jpg" alt=""></p><p>张国荣排在了第一位，这是之前没有猜到的。其次是梁朝伟和星爷，再之后是布拉德·皮特。惊奇地发现，前十名影星中，香港影星居然占了6位。有点严重怀疑这是不是香港版的top100电影。。。</p><p>对张国荣以7部影片的巨大优势雄霸榜单第一位感到好奇，想看看是哪7部电影。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'star1'</span>] = df[<span class="string">'star'</span>].map(<span class="keyword">lambda</span> x:x.split(<span class="string">','</span>)[<span class="number">0</span>])  <span class="comment">#提取1号演员</span></span><br><span class="line">df[<span class="string">'star2'</span>] = df[<span class="string">'star'</span>].map(<span class="keyword">lambda</span> x:x.split(<span class="string">','</span>)[<span class="number">1</span>])  <span class="comment">#提取2号演员</span></span><br><span class="line">star_most = df[(df.star1 == <span class="string">'张国荣'</span>) | (df.star2 == <span class="string">'张国荣'</span>)][[<span class="string">'star'</span>,<span class="string">'name'</span>]].reset_index(<span class="string">'index'</span>)</span><br><span class="line"><span class="comment"># |表示两个条件或查询，之后重置索引</span></span><br><span class="line">print(star_most)</span><br></pre></td></tr></table></figure></p><p>可以看到包括排名第1的”霸王别姬”、第17名的”春光乍泄”、第27名的”射雕英雄传之东成西就”等。<br>突然发现，好像只看过”英雄本色”。。。有时间，去看看他其他的作品。</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">     index        star              name</span><br><span class="line"><span class="number">0</span>      <span class="number">1</span>   张国荣,张丰毅,巩俐        霸王别姬</span><br><span class="line"><span class="number">1</span>     <span class="number">17</span>   张国荣,梁朝伟,张震        春光乍泄</span><br><span class="line"><span class="number">2</span>     <span class="number">27</span>  张国荣,梁朝伟,张学友  射雕英雄传之东成西就</span><br><span class="line"><span class="number">3</span>     <span class="number">37</span>  张国荣,梁朝伟,刘嘉玲        东邪西毒</span><br><span class="line"><span class="number">4</span>     <span class="number">70</span>   张国荣,王祖贤,午马        倩女幽魂</span><br><span class="line"><span class="number">5</span>     <span class="number">99</span>  张国荣,张曼玉,刘德华        阿飞正传</span><br><span class="line"><span class="number">6</span>    <span class="number">100</span>   狄龙,张国荣,周润发        英雄本色</span><br></pre></td></tr></table></figure><p>由于数据量有限，故仅作了上述简要的分析。</p><h3 id="4-4-完整程序"><a href="#4-4-完整程序" class="headerlink" title="4.4. 完整程序"></a>4.4. 完整程序</h3><p>最后，将前面爬虫的所有代码整理一下，完整的代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> requests.exceptions <span class="keyword">import</span> RequestException</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="comment"># -----------------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_one_page</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        headers = &#123;</span><br><span class="line">            <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'</span>&#125;</span><br><span class="line">        <span class="comment"># 不加headers爬不了</span></span><br><span class="line">        response = requests.get(url, headers=headers)</span><br><span class="line">        <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> response.text</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line">    <span class="keyword">except</span> RequestException:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1 用正则提取内容</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_one_page</span><span class="params">(html)</span>:</span></span><br><span class="line">    pattern = re.compile(</span><br><span class="line">        <span class="string">'&lt;dd&gt;.*?board-index.*?&gt;(\d+)&lt;/i&gt;.*?data-src="(.*?)".*?name"&gt;&lt;a.*?&gt;(.*?)&lt;/a&gt;.*?star"&gt;(.*?)&lt;/p&gt;.*?releasetime"&gt;(.*?)&lt;/p.*?integer"&gt;(.*?)&lt;/i&gt;.*?fraction"&gt;(.*?)&lt;/i&gt;.*?&lt;/dd&gt;'</span>, re.S)</span><br><span class="line">    <span class="comment"># re.S表示匹配任意字符，如果不加.无法匹配换行符</span></span><br><span class="line">    items = re.findall(pattern, html)</span><br><span class="line">    <span class="comment"># print(items)</span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="string">'index'</span>: item[<span class="number">0</span>],</span><br><span class="line">            <span class="string">'thumb'</span>: get_thumb(item[<span class="number">1</span>]),</span><br><span class="line">            <span class="string">'name'</span>: item[<span class="number">2</span>],</span><br><span class="line">            <span class="string">'star'</span>: item[<span class="number">3</span>].strip()[<span class="number">3</span>:],</span><br><span class="line">            <span class="comment"># 'time': item[4].strip()[5:],</span></span><br><span class="line">            <span class="comment"># 用函数分别提取time里的日期和地区</span></span><br><span class="line">            <span class="string">'time'</span>: get_release_time(item[<span class="number">4</span>].strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'area'</span>: get_release_area(item[<span class="number">4</span>].strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'score'</span>: item[<span class="number">5</span>].strip() + item[<span class="number">6</span>].strip()</span><br><span class="line">        &#125;</span><br><span class="line">      </span><br><span class="line"><span class="comment"># 2 用lxml结合xpath提取内容</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_one_page2</span><span class="params">(html)</span>:</span></span><br><span class="line">    parse = etree.HTML(html)</span><br><span class="line">    items = parse.xpath(<span class="string">'//*[@id="app"]//div//dd'</span>)</span><br><span class="line">    <span class="comment"># 完整的是//*[@id="app"]/div/div/div[1]/dl/dd</span></span><br><span class="line">    <span class="comment"># print(type(items))</span></span><br><span class="line">    <span class="comment"># *代表匹配所有节点，@表示属性</span></span><br><span class="line">    <span class="comment"># 第一个电影是dd[1],要提取页面所有电影则去掉[1]</span></span><br><span class="line">    <span class="comment"># xpath://*[@id="app"]/div/div/div[1]/dl/dd[1]</span></span><br><span class="line">    <span class="comment"># lst = []</span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        <span class="keyword">yield</span>&#123;</span><br><span class="line">            <span class="string">'index'</span>: item.xpath(<span class="string">'./i/text()'</span>)[<span class="number">0</span>],</span><br><span class="line">            <span class="comment">#./i/text()前面的点表示从items节点开始</span></span><br><span class="line">            <span class="comment">#/text()提取文本</span></span><br><span class="line">            <span class="string">'thumb'</span>: get_thumb(str(item.xpath(<span class="string">'./a/img[2]/@data-src'</span>)[<span class="number">0</span>].strip())),</span><br><span class="line">            <span class="comment"># 'thumb': 要在network中定位，在elements里会写成@src而不是@data-src，从而会报list index out of range错误。</span></span><br><span class="line">            <span class="string">'name'</span>: item.xpath(<span class="string">'./a/@title'</span>)[<span class="number">0</span>],</span><br><span class="line">            <span class="string">'star'</span>: item.xpath(<span class="string">'.//p[@class = "star"]/text()'</span>)[<span class="number">0</span>].strip(),</span><br><span class="line">            <span class="string">'time'</span>: get_release_time(item.xpath(</span><br><span class="line">                <span class="string">'.//p[@class = "releasetime"]/text()'</span>)[<span class="number">0</span>].strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'area'</span>: get_release_area(item.xpath(</span><br><span class="line">                <span class="string">'.//p[@class = "releasetime"]/text()'</span>)[<span class="number">0</span>].strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'score'</span> : item.xpath(<span class="string">'.//p[@class = "score"]/i[1]/text()'</span>)[<span class="number">0</span>] + \</span><br><span class="line">            item.xpath(<span class="string">'.//p[@class = "score"]/i[2]/text()'</span>)[<span class="number">0</span>]</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 3 用beautifulsoup + css选择器提取</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_one_page3</span><span class="params">(html)</span>:</span></span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">'lxml'</span>)</span><br><span class="line">    <span class="comment"># print(content)</span></span><br><span class="line">    <span class="comment"># print(type(content))</span></span><br><span class="line">    <span class="comment"># print('------------')</span></span><br><span class="line">    items = range(<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        <span class="keyword">yield</span>&#123;</span><br><span class="line"></span><br><span class="line">            <span class="string">'index'</span>: soup.select(<span class="string">'dd i.board-index'</span>)[item].string,</span><br><span class="line">            <span class="comment"># iclass节点完整地为'board-index board-index-1',写board-inde即可</span></span><br><span class="line">            <span class="string">'thumb'</span>: get_thumb(soup.select(<span class="string">'a &gt; img.board-img'</span>)[item][<span class="string">"data-src"</span>]),</span><br><span class="line">            <span class="comment"># 表示a节点下面的class = board-img的img节点,注意浏览器eelement里面是src节点，而network里面是data-src节点，要用这个才能正确返回值</span></span><br><span class="line"></span><br><span class="line">            <span class="string">'name'</span>: soup.select(<span class="string">'.name a'</span>)[item].string,</span><br><span class="line">            <span class="string">'star'</span>: soup.select(<span class="string">'.star'</span>)[item].string.strip()[<span class="number">3</span>:],</span><br><span class="line">            <span class="string">'time'</span>: get_release_time(soup.select(<span class="string">'.releasetime'</span>)[item].string.strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'area'</span>: get_release_area(soup.select(<span class="string">'.releasetime'</span>)[item].string.strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'score'</span>: soup.select(<span class="string">'.integer'</span>)[item].string + soup.select(<span class="string">'.fraction'</span>)[item].string</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4 用beautifulsoup + find_all提取</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_one_page4</span><span class="params">(html)</span>:</span></span><br><span class="line">    soup = BeautifulSoup(html,<span class="string">'lxml'</span>)</span><br><span class="line">    items = range(<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        <span class="keyword">yield</span>&#123;</span><br><span class="line"></span><br><span class="line">            <span class="string">'index'</span>: soup.find_all(class_=<span class="string">'board-index'</span>)[item].string,</span><br><span class="line">            <span class="string">'thumb'</span>: soup.find_all(class_ = <span class="string">'board-img'</span>)[item].attrs[<span class="string">'data-src'</span>],</span><br><span class="line">            <span class="comment"># 用.get('data-src')获取图片src链接，或者用attrs['data-src']</span></span><br><span class="line">            <span class="string">'name'</span>: soup.find_all(name = <span class="string">'p'</span>,attrs = &#123;<span class="string">'class'</span> : <span class="string">'name'</span>&#125;)[item].string,</span><br><span class="line">            <span class="string">'star'</span>: soup.find_all(name = <span class="string">'p'</span>,attrs = &#123;<span class="string">'class'</span>:<span class="string">'star'</span>&#125;)[item].string.strip()[<span class="number">3</span>:],</span><br><span class="line">            <span class="string">'time'</span>: get_release_time(soup.find_all(class_ =<span class="string">'releasetime'</span>)[item].string.strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'area'</span>: get_release_time(soup.find_all(class_ =<span class="string">'releasetime'</span>)[item].string.strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'score'</span>:soup.find_all(name = <span class="string">'i'</span>,attrs = &#123;<span class="string">'class'</span>:<span class="string">'integer'</span>&#125;)[item].string.strip() + soup.find_all(name = <span class="string">'i'</span>,attrs = &#123;<span class="string">'class'</span>:<span class="string">'fraction'</span>&#125;)[item].string.strip()</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># -----------------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取时间函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_release_time</span><span class="params">(data)</span>:</span></span><br><span class="line">    pattern = re.compile(<span class="string">r'(.*?)(\(|$)'</span>)</span><br><span class="line">    items = re.search(pattern, data)</span><br><span class="line">    <span class="keyword">if</span> items <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'未知'</span></span><br><span class="line">    <span class="keyword">return</span> items.group(<span class="number">1</span>)  <span class="comment"># 返回匹配到的第一个括号(.*?)中结果即时间</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取国家/地区函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_release_area</span><span class="params">(data)</span>:</span></span><br><span class="line">    pattern = re.compile(<span class="string">r'.*\((.*)\)'</span>)</span><br><span class="line">    <span class="comment"># $表示匹配一行字符串的结尾，这里就是(.*?)；\(|$,表示匹配字符串含有(,或者只有(.*?)</span></span><br><span class="line">    items = re.search(pattern, data)</span><br><span class="line">    <span class="keyword">if</span> items <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'未知'</span></span><br><span class="line">    <span class="keyword">return</span> items.group(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取封面大图</span></span><br><span class="line"><span class="comment"># http://p0.meituan.net/movie/5420be40e3b755ffe04779b9b199e935256906.jpg@160w_220h_1e_1c</span></span><br><span class="line"><span class="comment"># 去掉@160w_220h_1e_1c就是大图</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_thumb</span><span class="params">(url)</span>:</span></span><br><span class="line">    pattern = re.compile(<span class="string">r'(.*?)@.*?'</span>)</span><br><span class="line">    thumb = re.search(pattern, url)</span><br><span class="line">    <span class="keyword">return</span> thumb.group(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据存储到csv</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_to_file3</span><span class="params">(item)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'猫眼top100.csv'</span>, <span class="string">'a'</span>, encoding=<span class="string">'utf_8_sig'</span>,newline=<span class="string">''</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="comment"># 'a'为追加模式（添加）</span></span><br><span class="line">        <span class="comment"># utf_8_sig格式导出csv不乱码 </span></span><br><span class="line">        fieldnames = [<span class="string">'index'</span>, <span class="string">'thumb'</span>, <span class="string">'name'</span>, <span class="string">'star'</span>, <span class="string">'time'</span>, <span class="string">'area'</span>, <span class="string">'score'</span>]</span><br><span class="line">        w = csv.DictWriter(f,fieldnames = fieldnames)</span><br><span class="line">        <span class="comment"># w.writeheader()</span></span><br><span class="line">        w.writerow(item)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 封面下载</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_thumb</span><span class="params">(name, url,num)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = requests.get(url)</span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">'封面图/'</span> + name + <span class="string">'.jpg'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(response.content)</span><br><span class="line">            print(<span class="string">'第%s部电影封面下载完毕'</span> %num)</span><br><span class="line">            print(<span class="string">'------'</span>)</span><br><span class="line">    <span class="keyword">except</span> RequestException <span class="keyword">as</span> e:</span><br><span class="line">        print(e)</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">     <span class="comment"># 存储格式是wb,因为图片是二进制数格式，不能用w，否则会报错</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># -----------------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(offset)</span>:</span></span><br><span class="line">    url = <span class="string">'http://maoyan.com/board/4?offset='</span> + str(offset)</span><br><span class="line">    html = get_one_page(url)</span><br><span class="line">    <span class="comment"># print(html)</span></span><br><span class="line">    <span class="comment"># parse_one_page2(html)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> parse_one_page(html):  <span class="comment"># 切换内容提取方法</span></span><br><span class="line">        print(item)</span><br><span class="line">        write_to_file(item)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 下载封面图</span></span><br><span class="line">        download_thumb(item[<span class="string">'name'</span>], item[<span class="string">'thumb'</span>],item[<span class="string">'index'</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># if __name__ == '__main__':</span></span><br><span class="line"><span class="comment">#     for i in range(10):</span></span><br><span class="line"><span class="comment">#         main(i * 10)</span></span><br><span class="line">        <span class="comment"># time.sleep(0.5)</span></span><br><span class="line">        <span class="comment"># 猫眼增加了反爬虫，设置0.5s的延迟时间</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2 使用多进程提升抓取效率</span></span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Pool</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    pool = Pool()</span><br><span class="line">    pool.map(main, [i * <span class="number">10</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>)])</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;b&gt;&lt;em&gt;python爬虫第1篇&lt;/em&gt;&lt;/b&gt;&lt;br&gt;利用Request请求库和4种内容提取方法：正则表达式、lxml+xpath、Beatutifulsoup+css选择器、Beatutifulsoup+find_all爬取网页内容。&lt;/p&gt;
    
    </summary>
    
      <category term="python爬虫" scheme="https://www.makcyun.top/categories/python%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="python爬虫" scheme="https://www.makcyun.top/tags/python%E7%88%AC%E8%99%AB/"/>
    
      <category term="requests" scheme="https://www.makcyun.top/tags/requests/"/>
    
      <category term="正则表达式" scheme="https://www.makcyun.top/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
    
      <category term="beautifulsoup" scheme="https://www.makcyun.top/tags/beautifulsoup/"/>
    
      <category term="css" scheme="https://www.makcyun.top/tags/css/"/>
    
      <category term="xpath" scheme="https://www.makcyun.top/tags/xpath/"/>
    
      <category term="lxml" scheme="https://www.makcyun.top/tags/lxml/"/>
    
  </entry>
  
  <entry>
    <title>4块钱,用Github+Hexo搭建你的个人博客：美化篇</title>
    <link href="https://www.makcyun.top/hexo02.html"/>
    <id>https://www.makcyun.top/hexo02.html</id>
    <published>2018-07-17T10:17:10.000Z</published>
    <updated>2018-08-16T09:26:53.010Z</updated>
    
    <content type="html"><![CDATA[<p>上一篇文章，介绍了如何搭建个人博客。这一篇文章则以我的博客为例详细介绍博客的美化步骤。</p><a id="more"></a><p>博客界面的美化需要修改源代码，对于没有前端基础的人来说，会比较费时间精力。即使一个小小的细节调整，可能就需要好一会儿，所以，需保持耐心。这里，以我的博客为例，介绍一些比较实用的元素美化操作。</p><h3 id="1-选择新的模板"><a href="#1-选择新的模板" class="headerlink" title="1 选择新的模板"></a>1 选择新的模板</h3><p>初始的博客界面使用的是<strong>landscape</strong>主题模板，非常难看。你需重新挑选一个好看的主题模板，然后在此基础上进行美化。<br><img src="http://pbscl931v.bkt.clouddn.com/18-7-14/90405263.jpg" alt=""></p><p><br></p><ul><li>在哪里找主题?<br>到这个<a href="https://github.com/search?o=desc&amp;q=topic%3Ahexo-theme&amp;s=stars&amp;type=Repositories" target="_blank" rel="noopener">hexo主题排名网站</a></li></ul><p><img src="http://pbscl931v.bkt.clouddn.com/FsgZW6JnrTdKpylVLyEORZbKJr9f" alt=""><br>可以看到，排名第一的是一款叫<strong>next</strong>的主题，那么就可以尝试用它作为博客主题。事实上，这款主题功能相当齐全，我使用的即是这款。</p><p>进入到这个主题，阅读<strong>README.md</strong>说明，可以详细了解这款主题如何使用，还可以查看一些使用了这款主题的博客。</p><ul><li>如何应用到自己的博客？  </li></ul><p>打开博客根目录下的<strong>themes文件夹</strong>，Git软件运行下述命令：</p><pre><code>git clone https://github.com/iissnan/hexo-theme-next themes/next</code></pre><p>就可以把这款主题的安装文件下载到电脑中。然后还打开<code>D:\blog\_config.yml</code>文件，找到 <code>theme</code> 字段，字段，并将其值更改为 <strong>hexo-theme-next</strong>（注意冒号后要留一个空格）。<br>这样，博客主题就切换为next主题了，下面进行一下验证。</p><ul><li>验证博客主题  </li></ul><p>在博客根目录下，运行下述命令：<br>    hexo clean<br>    hexo s -g</p><p>使用浏览器访问 <code>http://localhost:4000</code>,可以看到，你的博客已经完全变样，至少非常清爽了。<br><img src="http://pbscl931v.bkt.clouddn.com/FpHLTzWWl-JiakApNlw4nTH4hiin" alt=""></p><p>这是 NexT 默认的 scheme —— Muse。<br>NexT 一共有四个 scheme,分别是：  </p><ul><li>Muse: 默认 scheme，这是 NexT 最初的版本，黑白主调，大量留白  </li><li>Mist: Muse 的紧凑版本，整洁有序的单栏外观  </li><li>Pisces: 双栏 Scheme，小家碧玉似的清新   </li><li>Gemini: 左侧网站信息及目录，块+片段结构布局  </li></ul><p>我选用的是Pisces，下面以我的博客作为参照，介绍如何进行美化。  </p><p><img src="http://pbscl931v.bkt.clouddn.com/FrbdD-nXd6lA5e1AaVqi2EKJ-fwL" alt=""></p><p><strong>声明两个重要文件</strong><br>Hexo 中有两份主要的配置文件，其名称都是 <strong> _config.yml</strong>， 后续美化主要需要在这两个文件中进行内容修改。   </p><ul><li><p>站点配置文件，位于站点文件夹根目录内，主要包含 Hexo 本身的配置：<br>  /blog/_config.yml</p></li><li><p>主题配置文件，位于主题文件夹根目录内，主要用于配置主题相关的选项:<br>  ~/blog/themes/next/_config.yml</p></li></ul><p>为了描述方便，在以下说明中，将前者称为 <strong>站点配置文件</strong>， 后者称为 <strong>主题配置文件</strong>。</p><p><br></p><h3 id="2-布局修改设置"><a href="#2-布局修改设置" class="headerlink" title="2 布局修改设置"></a>2 布局修改设置</h3><p>将博客<br><img src="http://pbscl931v.bkt.clouddn.com/Fuh6fGK-0O74AFOQDhpwJ5M1iq_Z" alt=""></p><p><img src="http://pbscl931v.bkt.clouddn.com/FqCkbJiF0Xc4eBTU_xA5RXRAnr9o" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;上一篇文章，介绍了如何搭建个人博客。这一篇文章则以我的博客为例详细介绍博客的美化步骤。&lt;/p&gt;
    
    </summary>
    
      <category term="hexo博客" scheme="https://www.makcyun.top/categories/hexo%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="hexo" scheme="https://www.makcyun.top/tags/hexo/"/>
    
      <category term="个人博客" scheme="https://www.makcyun.top/tags/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"/>
    
      <category term="github" scheme="https://www.makcyun.top/tags/github/"/>
    
  </entry>
  
  <entry>
    <title>4块钱,用Github+Hexo搭建你的个人博客：搭建篇</title>
    <link href="https://www.makcyun.top/hexo01.html"/>
    <id>https://www.makcyun.top/hexo01.html</id>
    <published>2018-07-06T08:44:19.881Z</published>
    <updated>2018-08-16T09:27:15.222Z</updated>
    
    <content type="html"><![CDATA[<p><b><em>4块钱,你就能够在茫茫互联网中拥有一处专属于你的小天地，丈量你走过的每一个脚印。</em></b><br>之前，在网上看到过很多人拥有很酷的个人博客，很是羡慕，但感觉很难所以一直没敢去尝试。最近捣鼓了几天，发现搭建博客其实没有想象中的难。</p><a id="more"></a>  <p><strong>【更新于2018/7/14】</strong></p><p><strong>摘要：</strong> 对于一个不懂任何前端的纯小白来说，搭建博客是件很有挑战的事。好在参考了很多大佬的教程后顺利搭建完成，但过程中还是踩了一些坑。这里及时进行总结，作为博客的第一篇文章。</p><h2 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h2><h3 id="1-网上有很多现成的博客不用，为什么要自己搭建"><a href="#1-网上有很多现成的博客不用，为什么要自己搭建" class="headerlink" title="1 网上有很多现成的博客不用，为什么要自己搭建?"></a>1 网上有很多现成的博客不用，为什么要自己搭建?</h3><p>可能有人会说：很多网站都能写博客，而且博客现在其实都有点过时了，为什么还要自己去搞？  </p><p>这里我说一下我想自己搭建的两点原因：<br><strong>一、</strong>网上的多数博客大家都共用一套相同的模板界面，没有特点、界面也杂乱充斥着很多不相关的东西，不论是自己写还是给人看，体验都不好。<br><strong>二、</strong>拥有一个你自己可以起名字的博客网站，里面的任何内容完全由你自己决定，这感觉是件很酷的事。 </p><p>这些普通的网站博客和一些个人博客，哪个好看，高下立判吧。<br><img src="http://pbscl931v.bkt.clouddn.com/18-7-14/94423333.jpg" alt="新浪博客">  </p><p><center><strong>vs</strong></center><br><img src="http://pbscl931v.bkt.clouddn.com/18-7-14/12736339.jpg" alt="个人博客"></p><p>&nbsp;<br><img src="http://pbscl931v.bkt.clouddn.com/18-7-14/26966.jpg" alt="CSDN博客">  </p><p><center><strong>vs</strong></center><br><img src="http://pbscl931v.bkt.clouddn.com/18-7-14/73613801.jpg" alt="个人博客"></p><p>更多个人博客：<br><strong>litten</strong> &nbsp; <a href="http://litten.me/" target="_blank" rel="noopener">http://litten.me/</a><br><strong>Ryan</strong> &nbsp; <a href="http://ryane.top/" target="_blank" rel="noopener">http://ryane.top/</a><br><strong>liyin</strong> &nbsp; <a href="https://liyin.date/" target="_blank" rel="noopener">https://liyin.date/</a><br><strong>reuixiy</strong> &nbsp; <a href="https://reuixiy.github.io/" target="_blank" rel="noopener">https://reuixiy.github.io/</a><br><strong>Tranquilpeak</strong> &nbsp; <a href="https://louisbarranqueiro.github.io/hexo-theme-tranquilpeak/" target="_blank" rel="noopener">https://louisbarranqueiro.github.io/hexo-theme-tranquilpeak/</a></p><p><br></p><h3 id="2-搭建博客难不难？"><a href="#2-搭建博客难不难？" class="headerlink" title="2 搭建博客难不难？"></a>2 搭建博客难不难？</h3><p>我之前认为搭建博客是一件只有能程序猿才能做出来的高大上的活。其实，只要跟着网上的教程一步步做下去，一个小时不到就可以搭建好你自己的个人博客。所以，搭建博客其实很简单。只不过，如果你想把博客做得好看一些的话，才会花费一些精力。</p><p><br></p><h2 id="二、开始搭建博客"><a href="#二、开始搭建博客" class="headerlink" title="二、开始搭建博客"></a>二、开始搭建博客</h2><p><strong>如果看到上面那些精美的博客，你已经心动了，那就开始动手吧。下面正式开始博客搭建步骤。</strong>  </p><p><strong>搭建教程参考</strong><br>搭建博客的教程网上一搜一大堆，为了节省你的搜索时间，这里我筛选出了下面几篇很棒的教程，我基本都是跟着一步步做下来的。</p><ol><li><a href="https://my.oschina.net/ryaneLee/blog/638440" target="_blank" rel="noopener">小白独立搭建博客</a>   </li><li><a href="http://ryane.top/2018/01/10/2018%EF%BC%8C%E4%BD%A0%E8%AF%A5%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2%E4%BA%86%EF%BC%81/" target="_blank" rel="noopener">2018，你该搭建自己的博客了！</a></li><li><a href="https://blog.csdn.net/gdutxiaoxu/article/details/53576018" target="_blank" rel="noopener">手把手教你用Hexo+Github 搭建属于自己的博客</a></li></ol><p>操作平台:Win7 64位。</p><p><br></p><p><strong>相关名词解释：</strong><br><strong>Hexo：</strong>一种常用的博客框架，有了它建立博客非常简单。你可以认为它是一种博客模板，只不过它比普通网站的那种博客模板要好看地多，并且有很高度的自定义性，只要你愿意，你可以建立一个独一无二的博客来。<br>若想详细了解Hexo的使用，移步 <strong>Hexo官方网站</strong> <a href="https://hexo.io/zh-cn/docs/" target="_blank" rel="noopener">https://hexo.io/zh-cn/docs/</a>。  </p><p><strong>Github：</strong>一个全世界程序猿聚集的知名网站。免费的远程仓库和开源协作社区。我们需要利用网站里的Github Pages功能来托管需发布到网上的博客的相关文件和代码。</p><p><strong>Git：</strong> 一种版本控制系统。我们在自己的本地电脑写博客，如何把博客同步到Github，然后发布到网上去？就需要用这个软件去写几行代码然后就能搞定，后期用的最多的就是它。</p><p><strong>Node.js：</strong> 提供JavaScript的开发环境，安装好以后就不用跟它再打交道，所以不用太关注它。</p><h3 id="1-软件安装配置"><a href="#1-软件安装配置" class="headerlink" title="1 软件安装配置"></a>1 软件安装配置</h3><p>搭建博客需要先下载2个软件：Git和Nodejs。<br>软件安装过程很简单，一直点击Next默认直到安装完成就行了。</p><p><strong>Git</strong><br>官网：<a href="https://git-scm.com/download/win" target="_blank" rel="noopener">https://git-scm.com/download/win</a><br>安装完，打开cmd窗口运行下面命令，如果有返回版本信息说明安装成功。</p><pre><code>git –version </code></pre><p><strong>Nodejs</strong><br>官网：<a href="https://nodejs.org/en/download/" target="_blank" rel="noopener">https://nodejs.org/en/download/</a><br>同样，安装完有返回版本信息说明安装成功，见下图。</p><pre><code>node -v  npm -v  </code></pre><p><img src="http://pbscl931v.bkt.clouddn.com/18-7-14/43008634.jpg" alt="cmd命令"></p><p>至此，软件安装步骤完成。</p><h3 id="2-安装Hexo博客框架"><a href="#2-安装Hexo博客框架" class="headerlink" title="2 安装Hexo博客框架"></a>2 安装Hexo博客框架</h3><ul><li>安装hexo  </li></ul><p>这里开始就要用到使用频率最高的Git软件了。</p><p>桌面右键点击<strong>git bash here</strong>选项，会打开Git软件界面，输入下面每行命令并回车：  </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-cli -g</span><br><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure><p>第一句是安装hexo，第二句是安装hexo部署到git page的deployer。代码命令看不懂没关系，一是这些命令之后几乎不再用到，二是用多了你会慢慢记住。<br><img src="http://pbscl931v.bkt.clouddn.com/18-7-14/18599032.jpg" alt="">  </p><ul><li>设置博客存放文件夹  </li></ul><p>你需要预想一下你要把博客文件新建在哪个盘下的文件夹里，除了c盘都可以，例如d盘根目录下的blog文件夹，紧接着在桌面输入下面命令并回车：  </p><pre><code>hexo init /d/blogcd /d/blognpm install*注：/d/bog可以更改为你自己的文件夹*</code></pre><p>有的教程是先新建博客文件夹，在该文件夹下右键鼠标，点击Git Bash Here，进入Git命令框，再执行以下操作。但是我操作过程中出现过这样的失败提示：<code>hexo:conmand not found</code>，但我执行上面的命令时就没有出现该问题。</p><pre><code>hexo init npm install</code></pre><ul><li>查看博客效果  </li></ul><p>至此，博客初步搭建好，输入下面一行本地部署生成的命令：  </p><pre><code>hexo s -g </code></pre><p>然后打开浏览器在网址栏输入：<code>localhost:4000</code>就可以看到博客的样子，如果无法打开，则继续输入下面命令：    </p><pre><code>npm install hexo-deployer-git --savehexo cleanhexo s -g </code></pre><p><img src="http://pbscl931v.bkt.clouddn.com/18-7-14/90405263.jpg" alt="">  </p><p>打开该网址，你可以看到第一篇默认的博客：<strong>Hello World</strong>。但看起来很难看，后续会通过重新选择模板来对博客进行美化。  </p><div class="note primary"><p>现在你就可以开始写博客了，但是博客只能在你自己的电脑上看到，别人无法在网上看到你的博客。接下来需要利用前面提到的的Github Pages功能进行设置，设置完成之后别人通过搜索就可以看到你的博客。</p></div><h3 id="3-把你的博客部署到Github-Pages上去"><a href="#3-把你的博客部署到Github-Pages上去" class="headerlink" title="3 把你的博客部署到Github Pages上去"></a>3 把你的博客部署到Github Pages上去</h3><p>这是搭建博客相对比较复杂也是容易出错的一部分。</p><p><strong>1. Github账号注册及配置</strong>  </p><p>如果你没有github帐号，就新建一个，然后去邮箱进行验证；如果你有帐号则直接登录。<br>官网：<a href="https://github.com/" target="_blank" rel="noopener">https://github.com/</a> </p><p>配置步骤：  </p><ul><li>建立new repository</li></ul><p>只填写username.github.io即可，然后点击<code>create repositrory</code>。<br>注意：<code>username.github.io</code> 的<code>username</code>要和用户名保持一致，不然后面会失败。以我的为例：  </p><p><img src="http://pbscl931v.bkt.clouddn.com/18-7-14/98355992.jpg" alt="1"></p><p><img src="http://pbscl931v.bkt.clouddn.com/18-7-14/62084844.jpg" alt="2"></p><ul><li>开启gh-pages功能  </li></ul><p>点击github主页点击头像下面的profile,找到新建立的username.github.io文件打开，点击settings，往下拉动鼠标到GitHub Pages。<br>如果你看到上方出现以下警告：  </p><div class="note warning"><br>GitHub Pages is currently disabled. You must first add content to your repository before you can publish a GitHub Pages site<br></div><p>不用管他，点击选择<code>choose a theme</code>，随便选择一个，（之后我们要更改这些丑陋的模板），然后select theme保存就行了。</p><p><img src="http://pbscl931v.bkt.clouddn.com/18-7-14/79896859.jpg" alt="3"></p><p><img src="http://pbscl931v.bkt.clouddn.com/18-7-14/1269326.jpg" alt="5"> </p><p>接下来的几个步骤参考<a href="https://my.oschina.net/ryaneLee/blog/638440" target="_blank" rel="noopener">教程1</a>即可。  </p><p>主要步骤包括：  </p><ul><li>git创建SSH密钥  </li><li>在GitHub账户中添加你的公钥  </li><li>测试成功并设置用户信息  </li><li>将本地的Hexo文件更新到Github库中  </li><li>hexo部署更新博客  </li></ul><p>经过以上几步的操作，顺利的话，你的博客可以发布到网上，其他人也可以通过你的网址<code>username.github.io</code>（我的是<code>makcyun.github.io</code>）<br>访问到你的博客。  </p><h3 id="4-赶紧新建个博客试试"><a href="#4-赶紧新建个博客试试" class="headerlink" title="4 赶紧新建个博客试试"></a>4 赶紧新建个博客试试</h3><p>接下来你可以自己新建一个文档来写下你的第一篇博客并在网页上测试。</p><p>同样在根目录<code>D:\blog</code>中运行下面命令：  </p><pre><code>hexo new 第一篇博客*注：第一篇博客名称可以随便修改*</code></pre><p>然后打开<code>D:\blog\source\_posts</code>文件夹，就可以看到一个<code>第一篇博客.md</code>的文件。用支持markdown语法的软件打开该文件进行编辑即可。</p><p>编辑好以后，运行下述命令：</p><pre><code>hexo cleanhexo d -g</code></pre><p>然后，在网址中输入<code>username.github.io</code>即可看到你的博客上，出现<strong>第一篇博客</strong>这篇新的文章。</p><p><strong>至此，你的个人博客初步搭建过程就完成了。</strong></p><p><br></p><p>但是，现在还存在两个问题你可能想解决：</p><ul><li>markdown语法是什么，如何用软件编写博客？</li><li>网址是<code>username.github.io</code>，感觉很奇怪，而我的博客网址怎么是<strong>www</strong>开头的？</li></ul><p>好，下面来讲解一下。</p><p><br></p><p><strong>第一个问题</strong></p><p>关于markdown语法介绍：<br><a href="https://www.jianshu.com/p/1e402922ee32/" target="_blank" rel="noopener">markdown——入门指南</a></p><p>当你大致了解markdown语法后，如何用markdown写博客呢？不妨参考这两篇详细教程：  </p><blockquote><p><a href="https://markdown.tw/" target="_blank" rel="noopener">Markdown語法說明</a><br><a href="https://www.ofind.cn/archives/" target="_blank" rel="noopener">HEXO下的Markdown语法(GFM)写博客</a></p></blockquote><p>接下来你要一个可以写markdown语法的软件，这里推荐两款软件。  </p><p>Windows下使用<a href="http://markdownpad.com/" target="_blank" rel="noopener">Markdown Pad2</a>, Mac下使用<a href="http://25.io/mou/" target="_blank" rel="noopener">Mou</a>。 </p><p>我用的是Markdown Pad2，这款软件是付费软件，但网上有很多破解版，我这里将软件上传到了百度网盘，如需请取。<br>MarkdownPad2： <a href="https://pan.baidu.com/s/1NHA-E83pxKfm2he0WJxXPA" target="_blank" rel="noopener">https://pan.baidu.com/s/1NHA-E83pxKfm2he0WJxXPA</a>   密码：y9zh</p><p>安装好后，就可以打开刚才的<code>第一篇博客.md</code>，开始尝试写你的第一篇博客了。  </p><p>比如这是我用markdownpad写的博客原稿。<br><img src="http://pbscl931v.bkt.clouddn.com/FpU5NFP6QFdTwqjStlUrBNk2GPDK" alt=""></p><p>可以看到文档里面都是字符，没有图片这些。所以只需要用键盘专注于打字就行了，不需要像word那么复杂，还要用鼠标插入标题样式、图片这些操作。</p><p><br></p><p><strong>第二个问题</strong></p><p>我的网址不是默认的<code>username.github.io</code>，是因为我购买了一个域名，然后和<code>username.github.io</code>进行了关联，这样我的博客网址变成了我的域名。</p><p>在哪里购买域名呢？<br>首推去 <a href="https://wanwang.aliyun.com/domain/?spm=5176.383338.1907008.1.LWIFhw" target="_blank" rel="noopener">阿里云官网</a> 购买。</p><p>你可以随意起你喜欢的名字，然后在该网站进行搜索，没有人占用的话你就可以购买该域名。不同的后缀价格不同。可以看到<strong>.com</strong>、 <strong>.net</strong>等会比较贵，最便宜的这两年新出的<strong>.top域名</strong>，只要4块钱一年，我购买的就是这种。</p><p>购买完域名以后，需要做以下几个步骤：  </p><ul><li>实名认证</li><li>修改DNS</li><li>域名解析</li><li>新建CNAME文件</li></ul><p><strong>1 实名认证</strong><br>在修改DNS之前，必须要阿里云官网实名认证成功，用淘宝账户登录然后填写相关信息即可。</p><p><strong>2 修改DNS</strong><br>实名认证成功后，进入管理界面，依次点击：<br><img src="http://pbscl931v.bkt.clouddn.com/Ft9CnDVTNm1WFZMegkca8SaOokfW" alt=""></p><p><img src="http://pbscl931v.bkt.clouddn.com/FtOks38CUKdJga4Q-rlSXjcdezPs" alt=""></p><p>修改DNS为：<br><strong>f1g1ns1.dnspod.net<br>f1g1ns2.dnspod.net</strong></p><p><strong>3 域名解析</strong><br>DNS修改好以后，到<strong>DNSPOD</strong>这个网站去解析你的域名。  </p><p>首先，微信登录并注册 <a href="https://www.dnspod.cn/" target="_blank" rel="noopener">https://www.dnspod.cn/</a>，点击域名解析，添加上你的域名。<br><img src="http://pbscl931v.bkt.clouddn.com/FuS2HLF9F9v9wvYiloqF8kpWMh8V" alt=""></p><p>接着，添加以下两条记录即可。</p><p><img src="http://pbscl931v.bkt.clouddn.com/FojJP59gDAOuk41RMtCvEkuKijo2" alt=""></p><p>注意：<strong>makcyun.github.io.</strong>需换成你自己的名称，另外最后有一个<strong>“.”</strong></p><p><strong>4 新建CNAME文件</strong><br>在博客根目录文件夹下,例如我的<code>D:\blog\source</code>，新建名为<strong>CNAME</strong>的记事本文件，去掉后缀。<br>在里面输入你的域名，例如我的：<strong><a href="http://www.makcyun.top">www.makcyun.top</a></strong>即可，保存并关闭。</p><p><img src="http://pbscl931v.bkt.clouddn.com/FmmCR8YMx-heNEiN9RFb4MkEbFA0" alt=""></p><p><strong>注意： </strong><br>这里填不填写<strong>www</strong>前缀都是可以的，区别在于填写www，那么博客网址就会以www开头，例如：<strong><a href="http://www.makcyun.top">www.makcyun.top</a></strong>；如果不填写，博客网址是：<strong>makcyun.top</strong>，二者都可以，看你喜欢。</p><p>完成以上4步之后，根目录下再次运行：  </p><pre><code>hexo d -g  </code></pre><p>这时，输入你在记事本里的域名网址，即可打开你的博客。<br>至此，你的博客就换成了你想要的网址，别人也可以通过这个网址访问到你的博客。 </p><p><br></p><p>到这里，博客的初步搭建就算完成了，顺利的话不到1小时就能完成，如果中间出现差错，保持耐心多试几次应该就没问题。  </p><p>此时，还有一个比较重要的问题就是，你可能会觉得你的博客不够美观，不如我博客里前面提到的那几个博客，甚至也没有我的好看。  </p><p>如果你还愿意折腾的话，下一篇文章，我会以我的博客为例，讲一讲如何进行博客的美化。</p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;b&gt;&lt;em&gt;4块钱,你就能够在茫茫互联网中拥有一处专属于你的小天地，丈量你走过的每一个脚印。&lt;/em&gt;&lt;/b&gt;&lt;br&gt;之前，在网上看到过很多人拥有很酷的个人博客，很是羡慕，但感觉很难所以一直没敢去尝试。最近捣鼓了几天，发现搭建博客其实没有想象中的难。&lt;/p&gt;
    
    </summary>
    
      <category term="hexo博客" scheme="https://www.makcyun.top/categories/hexo%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="hexo" scheme="https://www.makcyun.top/tags/hexo/"/>
    
      <category term="个人博客" scheme="https://www.makcyun.top/tags/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"/>
    
      <category term="github" scheme="https://www.makcyun.top/tags/github/"/>
    
  </entry>
  
</feed>
